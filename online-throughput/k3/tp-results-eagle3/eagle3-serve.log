[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:29 [api_server.py:872] vLLM API server version 0.1.dev13107+ge1a34c3a5
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:29 [utils.py:267] non-default args: {'model_tag': 'meta-llama/Llama-3.3-70B-Instruct', 'disable_uvicorn_access_log': True, 'model': 'meta-llama/Llama-3.3-70B-Instruct', 'max_model_len': 5000, 'tensor_parallel_size': 2, 'enable_prefix_caching': False, 'max_num_seqs': 256, 'speculative_config': {'method': 'eagle3', 'model': 'yuhuili/EAGLE3-LLaMA3.3-Instruct-70B', 'num_speculative_tokens': 3}}
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:30 [model.py:541] Resolved architecture: LlamaForCausalLM
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:30 [model.py:1559] Using max model len 5000
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:31 [model.py:541] Resolved architecture: LlamaForCausalLM
[0;36m(APIServer pid=53538)[0;0m WARNING 01-27 14:49:31 [model.py:1883] Casting torch.float16 to torch.bfloat16.
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:31 [model.py:1559] Using max model len 2048
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:31 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=8192.
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:31 [vllm.py:618] Asynchronous scheduling is enabled.
[0;36m(APIServer pid=53538)[0;0m INFO 01-27 14:49:31 [vllm.py:625] Disabling NCCL for DP synchronization when using async scheduling.
[0;36m(EngineCore_DP0 pid=53735)[0;0m INFO 01-27 14:49:38 [core.py:96] Initializing a V1 LLM engine (v0.1.dev13107+ge1a34c3a5) with config: model='meta-llama/Llama-3.3-70B-Instruct', speculative_config=SpeculativeConfig(method='eagle3', model='yuhuili/EAGLE3-LLaMA3.3-Instruct-70B', num_spec_tokens=3), tokenizer='meta-llama/Llama-3.3-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=meta-llama/Llama-3.3-70B-Instruct, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=53735)[0;0m WARNING 01-27 14:49:38 [multiproc_executor.py:897] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 01-27 14:49:43 [parallel_state.py:1212] world_size=2 rank=1 local_rank=1 distributed_init_method=tcp://127.0.0.1:56401 backend=nccl
INFO 01-27 14:49:43 [parallel_state.py:1212] world_size=2 rank=0 local_rank=0 distributed_init_method=tcp://127.0.0.1:56401 backend=nccl
INFO 01-27 14:49:43 [pynccl.py:111] vLLM is using nccl==2.27.5
WARNING 01-27 14:49:43 [symm_mem.py:99] SymmMemCommunicator: symmetric memory initialization failed: CUDA driver error: invalid device ordinal Communicator is not available. To suppress this warning set VLLM_ALLREDUCE_USE_SYMM_MEM=0
WARNING 01-27 14:49:43 [symm_mem.py:99] SymmMemCommunicator: symmetric memory initialization failed: CUDA driver error: invalid device ordinal Communicator is not available. To suppress this warning set VLLM_ALLREDUCE_USE_SYMM_MEM=0
WARNING 01-27 14:49:43 [custom_all_reduce.py:165] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-27 14:49:43 [custom_all_reduce.py:165] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
INFO 01-27 14:49:43 [parallel_state.py:1423] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A
INFO 01-27 14:49:43 [parallel_state.py:1423] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 1, EP rank N/A
ERROR 01-27 14:49:44 [multiproc_executor.py:766] WorkerProc failed to start.
ERROR 01-27 14:49:44 [multiproc_executor.py:766] Traceback (most recent call last):
ERROR 01-27 14:49:44 [multiproc_executor.py:766]   File "/home/shadeform/code/vllm/vllm/v1/executor/multiproc_executor.py", line 737, in worker_main
ERROR 01-27 14:49:44 [multiproc_executor.py:766]     worker = WorkerProc(*args, **kwargs)
ERROR 01-27 14:49:44 [multiproc_executor.py:766]   File "/home/shadeform/code/vllm/vllm/v1/executor/multiproc_executor.py", line 566, in __init__
ERROR 01-27 14:49:44 [multiproc_executor.py:766]     self.worker.init_device()
ERROR 01-27 14:49:44 [multiproc_executor.py:766]   File "/home/shadeform/code/vllm/vllm/v1/worker/worker_base.py", line 326, in init_device
ERROR 01-27 14:49:44 [multiproc_executor.py:766]     self.worker.init_device()  # type: ignore
ERROR 01-27 14:49:44 [multiproc_executor.py:766]   File "/home/shadeform/code/vllm/vllm/v1/worker/gpu_worker.py", line 234, in init_device
ERROR 01-27 14:49:44 [multiproc_executor.py:766]     self.requested_memory = request_memory(init_snapshot, self.cache_config)
ERROR 01-27 14:49:44 [multiproc_executor.py:766]   File "/home/shadeform/code/vllm/vllm/v1/worker/utils.py", line 260, in request_memory
ERROR 01-27 14:49:44 [multiproc_executor.py:766]     raise ValueError(
ERROR 01-27 14:49:44 [multiproc_executor.py:766] ValueError: Free memory on device cuda:0 (1.13/79.1 GiB) on startup is less than desired GPU memory utilization (0.9, 71.19 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
INFO 01-27 14:49:44 [multiproc_executor.py:724] Parent process exited, terminating worker
INFO 01-27 14:49:44 [multiproc_executor.py:724] Parent process exited, terminating worker
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/engine/core.py", line 926, in run_engine_core
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     engine_core = EngineCoreProc(*args, engine_index=dp_rank, **kwargs)
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/engine/core.py", line 691, in __init__
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     super().__init__(
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/engine/core.py", line 105, in __init__
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     self.model_executor = executor_class(vllm_config)
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/executor/multiproc_executor.py", line 97, in __init__
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     super().__init__(vllm_config)
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/executor/abstract.py", line 101, in __init__
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     self._init_executor()
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/executor/multiproc_executor.py", line 165, in _init_executor
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     self.workers = WorkerProc.wait_for_ready(unready_workers)
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]   File "/home/shadeform/code/vllm/vllm/v1/executor/multiproc_executor.py", line 675, in wait_for_ready
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935]     raise e from None
[0;36m(EngineCore_DP0 pid=53735)[0;0m ERROR 01-27 14:49:45 [core.py:935] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:14 [loggers.py:257] Engine 000: Avg prompt throughput: 20.7 tokens/s, Avg generation throughput: 12.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.05, Accepted throughput: 0.42 tokens/s, Drafted throughput: 0.62 tokens/s, Accepted: 86 tokens, Drafted: 126 tokens, Per-position acceptance rate: 0.762, 0.690, 0.595, Avg Draft acceptance rate: 68.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:24 [loggers.py:257] Engine 000: Avg prompt throughput: 70.3 tokens/s, Avg generation throughput: 55.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.98, Accepted throughput: 36.80 tokens/s, Drafted throughput: 55.80 tokens/s, Accepted: 368 tokens, Drafted: 558 tokens, Per-position acceptance rate: 0.785, 0.629, 0.565, Avg Draft acceptance rate: 65.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:34 [loggers.py:257] Engine 000: Avg prompt throughput: 69.3 tokens/s, Avg generation throughput: 60.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.00, Accepted throughput: 40.30 tokens/s, Drafted throughput: 60.60 tokens/s, Accepted: 403 tokens, Drafted: 606 tokens, Per-position acceptance rate: 0.827, 0.644, 0.525, Avg Draft acceptance rate: 66.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:44 [loggers.py:257] Engine 000: Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 49.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.39, Accepted throughput: 28.40 tokens/s, Drafted throughput: 61.50 tokens/s, Accepted: 284 tokens, Drafted: 615 tokens, Per-position acceptance rate: 0.663, 0.424, 0.298, Avg Draft acceptance rate: 46.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:54 [loggers.py:257] Engine 000: Avg prompt throughput: 81.5 tokens/s, Avg generation throughput: 57.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:51:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.85, Accepted throughput: 37.00 tokens/s, Drafted throughput: 59.99 tokens/s, Accepted: 370 tokens, Drafted: 600 tokens, Per-position acceptance rate: 0.750, 0.600, 0.500, Avg Draft acceptance rate: 61.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:04 [loggers.py:257] Engine 000: Avg prompt throughput: 62.0 tokens/s, Avg generation throughput: 54.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.66, Accepted throughput: 33.90 tokens/s, Drafted throughput: 61.20 tokens/s, Accepted: 339 tokens, Drafted: 612 tokens, Per-position acceptance rate: 0.676, 0.554, 0.431, Avg Draft acceptance rate: 55.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:14 [loggers.py:257] Engine 000: Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 58.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 37.60 tokens/s, Drafted throughput: 61.19 tokens/s, Accepted: 376 tokens, Drafted: 612 tokens, Per-position acceptance rate: 0.760, 0.598, 0.485, Avg Draft acceptance rate: 61.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:24 [loggers.py:257] Engine 000: Avg prompt throughput: 56.4 tokens/s, Avg generation throughput: 58.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.89, Accepted throughput: 38.10 tokens/s, Drafted throughput: 60.60 tokens/s, Accepted: 381 tokens, Drafted: 606 tokens, Per-position acceptance rate: 0.782, 0.609, 0.495, Avg Draft acceptance rate: 62.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:34 [loggers.py:257] Engine 000: Avg prompt throughput: 63.3 tokens/s, Avg generation throughput: 58.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 37.70 tokens/s, Drafted throughput: 61.50 tokens/s, Accepted: 377 tokens, Drafted: 615 tokens, Per-position acceptance rate: 0.771, 0.615, 0.454, Avg Draft acceptance rate: 61.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:44 [loggers.py:257] Engine 000: Avg prompt throughput: 103.2 tokens/s, Avg generation throughput: 56.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.87, Accepted throughput: 37.00 tokens/s, Drafted throughput: 59.39 tokens/s, Accepted: 370 tokens, Drafted: 594 tokens, Per-position acceptance rate: 0.778, 0.626, 0.465, Avg Draft acceptance rate: 62.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:54 [loggers.py:257] Engine 000: Avg prompt throughput: 18.8 tokens/s, Avg generation throughput: 51.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:52:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.49, Accepted throughput: 30.80 tokens/s, Drafted throughput: 62.10 tokens/s, Accepted: 308 tokens, Drafted: 621 tokens, Per-position acceptance rate: 0.657, 0.464, 0.367, Avg Draft acceptance rate: 49.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:04 [loggers.py:257] Engine 000: Avg prompt throughput: 83.0 tokens/s, Avg generation throughput: 56.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.77, Accepted throughput: 36.00 tokens/s, Drafted throughput: 60.89 tokens/s, Accepted: 360 tokens, Drafted: 609 tokens, Per-position acceptance rate: 0.714, 0.581, 0.478, Avg Draft acceptance rate: 59.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:14 [loggers.py:257] Engine 000: Avg prompt throughput: 97.3 tokens/s, Avg generation throughput: 60.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.08, Accepted throughput: 40.90 tokens/s, Drafted throughput: 59.10 tokens/s, Accepted: 409 tokens, Drafted: 591 tokens, Per-position acceptance rate: 0.822, 0.701, 0.553, Avg Draft acceptance rate: 69.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:24 [loggers.py:257] Engine 000: Avg prompt throughput: 53.5 tokens/s, Avg generation throughput: 58.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.92, Accepted throughput: 38.50 tokens/s, Drafted throughput: 60.00 tokens/s, Accepted: 385 tokens, Drafted: 600 tokens, Per-position acceptance rate: 0.825, 0.620, 0.480, Avg Draft acceptance rate: 64.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:34 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:44 [loggers.py:257] Engine 000: Avg prompt throughput: 129.4 tokens/s, Avg generation throughput: 87.7 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.01, Accepted throughput: 29.20 tokens/s, Drafted throughput: 43.50 tokens/s, Accepted: 584 tokens, Drafted: 870 tokens, Per-position acceptance rate: 0.803, 0.641, 0.569, Avg Draft acceptance rate: 67.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:54 [loggers.py:257] Engine 000: Avg prompt throughput: 90.8 tokens/s, Avg generation throughput: 102.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:53:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.67, Accepted throughput: 63.80 tokens/s, Drafted throughput: 114.60 tokens/s, Accepted: 638 tokens, Drafted: 1146 tokens, Per-position acceptance rate: 0.728, 0.534, 0.408, Avg Draft acceptance rate: 55.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:04 [loggers.py:257] Engine 000: Avg prompt throughput: 120.8 tokens/s, Avg generation throughput: 104.8 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.73, Accepted throughput: 66.20 tokens/s, Drafted throughput: 114.89 tokens/s, Accepted: 662 tokens, Drafted: 1149 tokens, Per-position acceptance rate: 0.718, 0.564, 0.446, Avg Draft acceptance rate: 57.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:14 [loggers.py:257] Engine 000: Avg prompt throughput: 110.7 tokens/s, Avg generation throughput: 109.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.86, Accepted throughput: 71.20 tokens/s, Drafted throughput: 114.60 tokens/s, Accepted: 712 tokens, Drafted: 1146 tokens, Per-position acceptance rate: 0.762, 0.605, 0.497, Avg Draft acceptance rate: 62.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:24 [loggers.py:257] Engine 000: Avg prompt throughput: 166.5 tokens/s, Avg generation throughput: 106.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 68.29 tokens/s, Drafted throughput: 112.79 tokens/s, Accepted: 683 tokens, Drafted: 1128 tokens, Per-position acceptance rate: 0.750, 0.609, 0.457, Avg Draft acceptance rate: 60.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:34 [loggers.py:257] Engine 000: Avg prompt throughput: 101.8 tokens/s, Avg generation throughput: 99.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.59, Accepted throughput: 61.19 tokens/s, Drafted throughput: 115.19 tokens/s, Accepted: 612 tokens, Drafted: 1152 tokens, Per-position acceptance rate: 0.690, 0.513, 0.391, Avg Draft acceptance rate: 53.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:44 [loggers.py:257] Engine 000: Avg prompt throughput: 139.3 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.03, Accepted throughput: 75.79 tokens/s, Drafted throughput: 111.89 tokens/s, Accepted: 758 tokens, Drafted: 1119 tokens, Per-position acceptance rate: 0.818, 0.668, 0.547, Avg Draft acceptance rate: 67.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:54 [loggers.py:257] Engine 000: Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 24.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:54:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.67, Accepted throughput: 15.20 tokens/s, Drafted throughput: 27.30 tokens/s, Accepted: 152 tokens, Drafted: 273 tokens, Per-position acceptance rate: 0.747, 0.549, 0.374, Avg Draft acceptance rate: 55.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:04 [loggers.py:257] Engine 000: Avg prompt throughput: 144.6 tokens/s, Avg generation throughput: 87.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.04, Accepted throughput: 58.49 tokens/s, Drafted throughput: 86.09 tokens/s, Accepted: 585 tokens, Drafted: 861 tokens, Per-position acceptance rate: 0.812, 0.648, 0.578, Avg Draft acceptance rate: 67.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:14 [loggers.py:257] Engine 000: Avg prompt throughput: 196.4 tokens/s, Avg generation throughput: 186.9 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.66, Accepted throughput: 116.50 tokens/s, Drafted throughput: 210.00 tokens/s, Accepted: 1165 tokens, Drafted: 2100 tokens, Per-position acceptance rate: 0.713, 0.534, 0.417, Avg Draft acceptance rate: 55.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:24 [loggers.py:257] Engine 000: Avg prompt throughput: 231.0 tokens/s, Avg generation throughput: 200.8 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.88, Accepted throughput: 130.69 tokens/s, Drafted throughput: 209.09 tokens/s, Accepted: 1307 tokens, Drafted: 2091 tokens, Per-position acceptance rate: 0.769, 0.620, 0.486, Avg Draft acceptance rate: 62.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:34 [loggers.py:257] Engine 000: Avg prompt throughput: 222.8 tokens/s, Avg generation throughput: 188.3 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.72, Accepted throughput: 118.90 tokens/s, Drafted throughput: 207.90 tokens/s, Accepted: 1189 tokens, Drafted: 2079 tokens, Per-position acceptance rate: 0.714, 0.558, 0.443, Avg Draft acceptance rate: 57.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:44 [loggers.py:257] Engine 000: Avg prompt throughput: 76.0 tokens/s, Avg generation throughput: 84.9 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.01, Accepted throughput: 56.79 tokens/s, Drafted throughput: 84.59 tokens/s, Accepted: 568 tokens, Drafted: 846 tokens, Per-position acceptance rate: 0.848, 0.660, 0.507, Avg Draft acceptance rate: 67.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:54 [loggers.py:257] Engine 000: Avg prompt throughput: 160.3 tokens/s, Avg generation throughput: 50.9 tokens/s, Running: 8 reqs, Waiting: 0 reqs, GPU KV cache usage: 14.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:55:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.11, Accepted throughput: 34.00 tokens/s, Drafted throughput: 48.30 tokens/s, Accepted: 340 tokens, Drafted: 483 tokens, Per-position acceptance rate: 0.820, 0.696, 0.596, Avg Draft acceptance rate: 70.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:04 [loggers.py:257] Engine 000: Avg prompt throughput: 337.8 tokens/s, Avg generation throughput: 375.0 tokens/s, Running: 6 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.77, Accepted throughput: 239.19 tokens/s, Drafted throughput: 405.89 tokens/s, Accepted: 2392 tokens, Drafted: 4059 tokens, Per-position acceptance rate: 0.739, 0.571, 0.458, Avg Draft acceptance rate: 58.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:14 [loggers.py:257] Engine 000: Avg prompt throughput: 491.4 tokens/s, Avg generation throughput: 368.9 tokens/s, Running: 8 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.83, Accepted throughput: 237.68 tokens/s, Drafted throughput: 389.97 tokens/s, Accepted: 2377 tokens, Drafted: 3900 tokens, Per-position acceptance rate: 0.758, 0.602, 0.468, Avg Draft acceptance rate: 60.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:24 [loggers.py:257] Engine 000: Avg prompt throughput: 404.3 tokens/s, Avg generation throughput: 357.3 tokens/s, Running: 3 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.90, Accepted throughput: 234.18 tokens/s, Drafted throughput: 369.58 tokens/s, Accepted: 2342 tokens, Drafted: 3696 tokens, Per-position acceptance rate: 0.783, 0.629, 0.489, Avg Draft acceptance rate: 63.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:34 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 21.8 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.76, Accepted throughput: 13.90 tokens/s, Drafted throughput: 23.70 tokens/s, Accepted: 139 tokens, Drafted: 237 tokens, Per-position acceptance rate: 0.797, 0.544, 0.418, Avg Draft acceptance rate: 58.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:44 [loggers.py:257] Engine 000: Avg prompt throughput: 515.0 tokens/s, Avg generation throughput: 329.5 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.78, Accepted throughput: 209.70 tokens/s, Drafted throughput: 353.41 tokens/s, Accepted: 2097 tokens, Drafted: 3534 tokens, Per-position acceptance rate: 0.742, 0.570, 0.469, Avg Draft acceptance rate: 59.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:54 [loggers.py:257] Engine 000: Avg prompt throughput: 821.8 tokens/s, Avg generation throughput: 654.6 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:56:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.88, Accepted throughput: 426.38 tokens/s, Drafted throughput: 681.57 tokens/s, Accepted: 4264 tokens, Drafted: 6816 tokens, Per-position acceptance rate: 0.774, 0.619, 0.484, Avg Draft acceptance rate: 62.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:04 [loggers.py:257] Engine 000: Avg prompt throughput: 688.2 tokens/s, Avg generation throughput: 632.5 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 38.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.71, Accepted throughput: 399.48 tokens/s, Drafted throughput: 698.96 tokens/s, Accepted: 3995 tokens, Drafted: 6990 tokens, Per-position acceptance rate: 0.727, 0.560, 0.428, Avg Draft acceptance rate: 57.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:14 [loggers.py:257] Engine 000: Avg prompt throughput: 827.8 tokens/s, Avg generation throughput: 665.0 tokens/s, Running: 10 reqs, Waiting: 0 reqs, GPU KV cache usage: 26.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.99, Accepted throughput: 442.75 tokens/s, Drafted throughput: 665.93 tokens/s, Accepted: 4428 tokens, Drafted: 6660 tokens, Per-position acceptance rate: 0.796, 0.662, 0.536, Avg Draft acceptance rate: 66.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:24 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 67.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.73, Accepted throughput: 43.30 tokens/s, Drafted throughput: 75.00 tokens/s, Accepted: 433 tokens, Drafted: 750 tokens, Per-position acceptance rate: 0.740, 0.560, 0.432, Avg Draft acceptance rate: 57.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:34 [loggers.py:257] Engine 000: Avg prompt throughput: 689.9 tokens/s, Avg generation throughput: 384.4 tokens/s, Running: 32 reqs, Waiting: 0 reqs, GPU KV cache usage: 71.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.83, Accepted throughput: 246.20 tokens/s, Drafted throughput: 404.41 tokens/s, Accepted: 2462 tokens, Drafted: 4044 tokens, Per-position acceptance rate: 0.749, 0.592, 0.486, Avg Draft acceptance rate: 60.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1252.9 tokens/s, Avg generation throughput: 958.2 tokens/s, Running: 32 reqs, Waiting: 0 reqs, GPU KV cache usage: 68.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.81, Accepted throughput: 616.41 tokens/s, Drafted throughput: 1020.15 tokens/s, Accepted: 6165 tokens, Drafted: 10203 tokens, Per-position acceptance rate: 0.756, 0.597, 0.460, Avg Draft acceptance rate: 60.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1181.7 tokens/s, Avg generation throughput: 1002.6 tokens/s, Running: 32 reqs, Waiting: 0 reqs, GPU KV cache usage: 71.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:57:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.88, Accepted throughput: 653.69 tokens/s, Drafted throughput: 1043.53 tokens/s, Accepted: 6538 tokens, Drafted: 10437 tokens, Per-position acceptance rate: 0.771, 0.613, 0.495, Avg Draft acceptance rate: 62.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1227.6 tokens/s, Avg generation throughput: 969.9 tokens/s, Running: 32 reqs, Waiting: 0 reqs, GPU KV cache usage: 70.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.81, Accepted throughput: 623.96 tokens/s, Drafted throughput: 1032.68 tokens/s, Accepted: 6241 tokens, Drafted: 10329 tokens, Per-position acceptance rate: 0.748, 0.596, 0.469, Avg Draft acceptance rate: 60.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:14 [loggers.py:257] Engine 000: Avg prompt throughput: 1115.9 tokens/s, Avg generation throughput: 1014.2 tokens/s, Running: 30 reqs, Waiting: 0 reqs, GPU KV cache usage: 64.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.89, Accepted throughput: 663.95 tokens/s, Drafted throughput: 1055.02 tokens/s, Accepted: 6640 tokens, Drafted: 10551 tokens, Per-position acceptance rate: 0.768, 0.625, 0.495, Avg Draft acceptance rate: 62.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:24 [loggers.py:257] Engine 000: Avg prompt throughput: 183.7 tokens/s, Avg generation throughput: 392.7 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.75, Accepted throughput: 251.89 tokens/s, Drafted throughput: 430.78 tokens/s, Accepted: 2519 tokens, Drafted: 4308 tokens, Per-position acceptance rate: 0.743, 0.570, 0.441, Avg Draft acceptance rate: 58.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:34 [loggers.py:257] Engine 000: Avg prompt throughput: 551.6 tokens/s, Avg generation throughput: 33.2 tokens/s, Running: 64 reqs, Waiting: 0 reqs, GPU KV cache usage: 88.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.10, Accepted throughput: 20.40 tokens/s, Drafted throughput: 29.10 tokens/s, Accepted: 204 tokens, Drafted: 291 tokens, Per-position acceptance rate: 0.804, 0.711, 0.588, Avg Draft acceptance rate: 70.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1327.4 tokens/s, Avg generation throughput: 1051.8 tokens/s, Running: 51 reqs, Waiting: 13 reqs, GPU KV cache usage: 99.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 677.54 tokens/s, Drafted throughput: 1104.33 tokens/s, Accepted: 6777 tokens, Drafted: 11046 tokens, Per-position acceptance rate: 0.763, 0.601, 0.476, Avg Draft acceptance rate: 61.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1233.6 tokens/s, Avg generation throughput: 1052.1 tokens/s, Running: 46 reqs, Waiting: 15 reqs, GPU KV cache usage: 95.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:58:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 677.68 tokens/s, Drafted throughput: 1117.76 tokens/s, Accepted: 6777 tokens, Drafted: 11178 tokens, Per-position acceptance rate: 0.748, 0.599, 0.472, Avg Draft acceptance rate: 60.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1210.5 tokens/s, Avg generation throughput: 1038.6 tokens/s, Running: 48 reqs, Waiting: 13 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 670.46 tokens/s, Drafted throughput: 1095.54 tokens/s, Accepted: 6705 tokens, Drafted: 10956 tokens, Per-position acceptance rate: 0.756, 0.602, 0.478, Avg Draft acceptance rate: 61.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:14 [loggers.py:257] Engine 000: Avg prompt throughput: 1173.6 tokens/s, Avg generation throughput: 1094.1 tokens/s, Running: 43 reqs, Waiting: 18 reqs, GPU KV cache usage: 98.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.90, Accepted throughput: 715.70 tokens/s, Drafted throughput: 1128.30 tokens/s, Accepted: 7157 tokens, Drafted: 11283 tokens, Per-position acceptance rate: 0.774, 0.629, 0.500, Avg Draft acceptance rate: 63.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1321.1 tokens/s, Avg generation throughput: 1002.6 tokens/s, Running: 48 reqs, Waiting: 13 reqs, GPU KV cache usage: 95.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 645.12 tokens/s, Drafted throughput: 1061.73 tokens/s, Accepted: 6451 tokens, Drafted: 10617 tokens, Per-position acceptance rate: 0.759, 0.595, 0.469, Avg Draft acceptance rate: 60.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:34 [loggers.py:257] Engine 000: Avg prompt throughput: 1172.6 tokens/s, Avg generation throughput: 1090.6 tokens/s, Running: 43 reqs, Waiting: 17 reqs, GPU KV cache usage: 91.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.83, Accepted throughput: 702.93 tokens/s, Drafted throughput: 1151.74 tokens/s, Accepted: 7029 tokens, Drafted: 11517 tokens, Per-position acceptance rate: 0.758, 0.594, 0.479, Avg Draft acceptance rate: 61.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1334.9 tokens/s, Avg generation throughput: 1029.0 tokens/s, Running: 52 reqs, Waiting: 9 reqs, GPU KV cache usage: 99.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.85, Accepted throughput: 665.25 tokens/s, Drafted throughput: 1077.52 tokens/s, Accepted: 6653 tokens, Drafted: 10776 tokens, Per-position acceptance rate: 0.764, 0.605, 0.483, Avg Draft acceptance rate: 61.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1150.5 tokens/s, Avg generation throughput: 1038.8 tokens/s, Running: 43 reqs, Waiting: 21 reqs, GPU KV cache usage: 98.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 14:59:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.72, Accepted throughput: 654.93 tokens/s, Drafted throughput: 1144.21 tokens/s, Accepted: 6551 tokens, Drafted: 11445 tokens, Per-position acceptance rate: 0.729, 0.554, 0.433, Avg Draft acceptance rate: 57.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:00:04 [loggers.py:257] Engine 000: Avg prompt throughput: 665.8 tokens/s, Avg generation throughput: 895.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:00:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.78, Accepted throughput: 576.26 tokens/s, Drafted throughput: 968.64 tokens/s, Accepted: 5763 tokens, Drafted: 9687 tokens, Per-position acceptance rate: 0.739, 0.581, 0.465, Avg Draft acceptance rate: 59.5%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:00:14 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:24 [loggers.py:257] Engine 000: Avg prompt throughput: 20.7 tokens/s, Avg generation throughput: 10.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.15, Accepted throughput: 0.35 tokens/s, Drafted throughput: 0.49 tokens/s, Accepted: 71 tokens, Drafted: 99 tokens, Per-position acceptance rate: 0.788, 0.727, 0.636, Avg Draft acceptance rate: 71.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:34 [loggers.py:257] Engine 000: Avg prompt throughput: 70.3 tokens/s, Avg generation throughput: 55.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.98, Accepted throughput: 37.00 tokens/s, Drafted throughput: 56.10 tokens/s, Accepted: 370 tokens, Drafted: 561 tokens, Per-position acceptance rate: 0.781, 0.631, 0.567, Avg Draft acceptance rate: 66.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:44 [loggers.py:257] Engine 000: Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 61.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.01, Accepted throughput: 40.90 tokens/s, Drafted throughput: 60.89 tokens/s, Accepted: 409 tokens, Drafted: 609 tokens, Per-position acceptance rate: 0.837, 0.645, 0.532, Avg Draft acceptance rate: 67.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:54 [loggers.py:257] Engine 000: Avg prompt throughput: 52.9 tokens/s, Avg generation throughput: 48.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:03:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.39, Accepted throughput: 28.20 tokens/s, Drafted throughput: 60.89 tokens/s, Accepted: 282 tokens, Drafted: 609 tokens, Per-position acceptance rate: 0.665, 0.429, 0.296, Avg Draft acceptance rate: 46.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:04 [loggers.py:257] Engine 000: Avg prompt throughput: 81.5 tokens/s, Avg generation throughput: 57.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.87, Accepted throughput: 37.40 tokens/s, Drafted throughput: 60.00 tokens/s, Accepted: 374 tokens, Drafted: 600 tokens, Per-position acceptance rate: 0.745, 0.615, 0.510, Avg Draft acceptance rate: 62.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:14 [loggers.py:257] Engine 000: Avg prompt throughput: 44.7 tokens/s, Avg generation throughput: 53.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.59, Accepted throughput: 33.00 tokens/s, Drafted throughput: 62.10 tokens/s, Accepted: 330 tokens, Drafted: 621 tokens, Per-position acceptance rate: 0.667, 0.522, 0.406, Avg Draft acceptance rate: 53.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:24 [loggers.py:257] Engine 000: Avg prompt throughput: 71.6 tokens/s, Avg generation throughput: 56.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.81, Accepted throughput: 36.40 tokens/s, Drafted throughput: 60.30 tokens/s, Accepted: 364 tokens, Drafted: 603 tokens, Per-position acceptance rate: 0.751, 0.587, 0.473, Avg Draft acceptance rate: 60.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:34 [loggers.py:257] Engine 000: Avg prompt throughput: 56.4 tokens/s, Avg generation throughput: 59.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.94, Accepted throughput: 39.20 tokens/s, Drafted throughput: 60.60 tokens/s, Accepted: 392 tokens, Drafted: 606 tokens, Per-position acceptance rate: 0.797, 0.629, 0.515, Avg Draft acceptance rate: 64.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:44 [loggers.py:257] Engine 000: Avg prompt throughput: 63.3 tokens/s, Avg generation throughput: 57.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 37.40 tokens/s, Drafted throughput: 61.50 tokens/s, Accepted: 374 tokens, Drafted: 615 tokens, Per-position acceptance rate: 0.761, 0.610, 0.454, Avg Draft acceptance rate: 60.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:54 [loggers.py:257] Engine 000: Avg prompt throughput: 69.0 tokens/s, Avg generation throughput: 58.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:04:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.89, Accepted throughput: 38.10 tokens/s, Drafted throughput: 60.60 tokens/s, Accepted: 381 tokens, Drafted: 606 tokens, Per-position acceptance rate: 0.777, 0.639, 0.470, Avg Draft acceptance rate: 62.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:04 [loggers.py:257] Engine 000: Avg prompt throughput: 53.0 tokens/s, Avg generation throughput: 51.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.53, Accepted throughput: 31.30 tokens/s, Drafted throughput: 61.20 tokens/s, Accepted: 313 tokens, Drafted: 612 tokens, Per-position acceptance rate: 0.681, 0.475, 0.377, Avg Draft acceptance rate: 51.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:14 [loggers.py:257] Engine 000: Avg prompt throughput: 83.0 tokens/s, Avg generation throughput: 53.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.67, Accepted throughput: 33.80 tokens/s, Drafted throughput: 60.60 tokens/s, Accepted: 338 tokens, Drafted: 606 tokens, Per-position acceptance rate: 0.688, 0.545, 0.441, Avg Draft acceptance rate: 55.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:24 [loggers.py:257] Engine 000: Avg prompt throughput: 97.3 tokens/s, Avg generation throughput: 60.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.08, Accepted throughput: 41.00 tokens/s, Drafted throughput: 59.10 tokens/s, Accepted: 410 tokens, Drafted: 591 tokens, Per-position acceptance rate: 0.822, 0.701, 0.558, Avg Draft acceptance rate: 69.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:34 [loggers.py:257] Engine 000: Avg prompt throughput: 53.5 tokens/s, Avg generation throughput: 60.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.97, Accepted throughput: 39.80 tokens/s, Drafted throughput: 60.60 tokens/s, Accepted: 398 tokens, Drafted: 606 tokens, Per-position acceptance rate: 0.832, 0.639, 0.500, Avg Draft acceptance rate: 65.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:44 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.43, Accepted throughput: 1.00 tokens/s, Drafted throughput: 2.10 tokens/s, Accepted: 10 tokens, Drafted: 21 tokens, Per-position acceptance rate: 0.714, 0.429, 0.286, Avg Draft acceptance rate: 47.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:54 [loggers.py:257] Engine 000: Avg prompt throughput: 129.4 tokens/s, Avg generation throughput: 92.3 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:05:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.01, Accepted throughput: 61.40 tokens/s, Drafted throughput: 91.80 tokens/s, Accepted: 614 tokens, Drafted: 918 tokens, Per-position acceptance rate: 0.801, 0.637, 0.569, Avg Draft acceptance rate: 66.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:04 [loggers.py:257] Engine 000: Avg prompt throughput: 103.7 tokens/s, Avg generation throughput: 102.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.67, Accepted throughput: 63.59 tokens/s, Drafted throughput: 114.28 tokens/s, Accepted: 636 tokens, Drafted: 1143 tokens, Per-position acceptance rate: 0.730, 0.535, 0.404, Avg Draft acceptance rate: 55.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:14 [loggers.py:257] Engine 000: Avg prompt throughput: 107.9 tokens/s, Avg generation throughput: 105.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.73, Accepted throughput: 66.40 tokens/s, Drafted throughput: 115.20 tokens/s, Accepted: 664 tokens, Drafted: 1152 tokens, Per-position acceptance rate: 0.714, 0.565, 0.451, Avg Draft acceptance rate: 57.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:24 [loggers.py:257] Engine 000: Avg prompt throughput: 110.7 tokens/s, Avg generation throughput: 108.3 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.83, Accepted throughput: 69.89 tokens/s, Drafted throughput: 114.59 tokens/s, Accepted: 699 tokens, Drafted: 1146 tokens, Per-position acceptance rate: 0.757, 0.592, 0.482, Avg Draft acceptance rate: 61.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:34 [loggers.py:257] Engine 000: Avg prompt throughput: 166.5 tokens/s, Avg generation throughput: 107.7 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.86, Accepted throughput: 69.80 tokens/s, Drafted throughput: 112.79 tokens/s, Accepted: 698 tokens, Drafted: 1128 tokens, Per-position acceptance rate: 0.758, 0.625, 0.473, Avg Draft acceptance rate: 61.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:44 [loggers.py:257] Engine 000: Avg prompt throughput: 113.5 tokens/s, Avg generation throughput: 99.4 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.61, Accepted throughput: 61.39 tokens/s, Drafted throughput: 114.29 tokens/s, Accepted: 614 tokens, Drafted: 1143 tokens, Per-position acceptance rate: 0.696, 0.520, 0.396, Avg Draft acceptance rate: 53.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:54 [loggers.py:257] Engine 000: Avg prompt throughput: 127.6 tokens/s, Avg generation throughput: 113.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:06:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.00, Accepted throughput: 75.49 tokens/s, Drafted throughput: 113.39 tokens/s, Accepted: 755 tokens, Drafted: 1134 tokens, Per-position acceptance rate: 0.815, 0.656, 0.526, Avg Draft acceptance rate: 66.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:04 [loggers.py:257] Engine 000: Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 19.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.66, Accepted throughput: 12.10 tokens/s, Drafted throughput: 21.90 tokens/s, Accepted: 121 tokens, Drafted: 219 tokens, Per-position acceptance rate: 0.726, 0.534, 0.397, Avg Draft acceptance rate: 55.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:14 [loggers.py:257] Engine 000: Avg prompt throughput: 160.3 tokens/s, Avg generation throughput: 99.0 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.01, Accepted throughput: 65.80 tokens/s, Drafted throughput: 98.10 tokens/s, Accepted: 658 tokens, Drafted: 981 tokens, Per-position acceptance rate: 0.798, 0.645, 0.569, Avg Draft acceptance rate: 67.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:24 [loggers.py:257] Engine 000: Avg prompt throughput: 196.6 tokens/s, Avg generation throughput: 187.5 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 6.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.68, Accepted throughput: 117.29 tokens/s, Drafted throughput: 209.39 tokens/s, Accepted: 1173 tokens, Drafted: 2094 tokens, Per-position acceptance rate: 0.721, 0.540, 0.420, Avg Draft acceptance rate: 56.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:34 [loggers.py:257] Engine 000: Avg prompt throughput: 215.1 tokens/s, Avg generation throughput: 200.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.86, Accepted throughput: 130.30 tokens/s, Drafted throughput: 210.60 tokens/s, Accepted: 1303 tokens, Drafted: 2106 tokens, Per-position acceptance rate: 0.758, 0.613, 0.486, Avg Draft acceptance rate: 61.9%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:44 [loggers.py:257] Engine 000: Avg prompt throughput: 245.3 tokens/s, Avg generation throughput: 187.6 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 8.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.73, Accepted throughput: 118.91 tokens/s, Drafted throughput: 205.81 tokens/s, Accepted: 1189 tokens, Drafted: 2058 tokens, Per-position acceptance rate: 0.726, 0.563, 0.445, Avg Draft acceptance rate: 57.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:54 [loggers.py:257] Engine 000: Avg prompt throughput: 53.5 tokens/s, Avg generation throughput: 73.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:07:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.99, Accepted throughput: 48.90 tokens/s, Drafted throughput: 73.80 tokens/s, Accepted: 489 tokens, Drafted: 738 tokens, Per-position acceptance rate: 0.829, 0.646, 0.512, Avg Draft acceptance rate: 66.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:04 [loggers.py:257] Engine 000: Avg prompt throughput: 160.3 tokens/s, Avg generation throughput: 93.1 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.03, Accepted throughput: 61.89 tokens/s, Drafted throughput: 91.49 tokens/s, Accepted: 619 tokens, Drafted: 915 tokens, Per-position acceptance rate: 0.807, 0.666, 0.557, Avg Draft acceptance rate: 67.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:14 [loggers.py:257] Engine 000: Avg prompt throughput: 423.6 tokens/s, Avg generation throughput: 368.0 tokens/s, Running: 8 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.77, Accepted throughput: 234.57 tokens/s, Drafted throughput: 397.45 tokens/s, Accepted: 2346 tokens, Drafted: 3975 tokens, Per-position acceptance rate: 0.740, 0.573, 0.457, Avg Draft acceptance rate: 59.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:24 [loggers.py:257] Engine 000: Avg prompt throughput: 444.8 tokens/s, Avg generation throughput: 368.7 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 13.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.80, Accepted throughput: 236.70 tokens/s, Drafted throughput: 393.60 tokens/s, Accepted: 2367 tokens, Drafted: 3936 tokens, Per-position acceptance rate: 0.749, 0.595, 0.460, Avg Draft acceptance rate: 60.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:34 [loggers.py:257] Engine 000: Avg prompt throughput: 365.0 tokens/s, Avg generation throughput: 336.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 6.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.91, Accepted throughput: 220.60 tokens/s, Drafted throughput: 347.10 tokens/s, Accepted: 2206 tokens, Drafted: 3471 tokens, Per-position acceptance rate: 0.790, 0.627, 0.490, Avg Draft acceptance rate: 63.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:44 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.00, Accepted throughput: 5.20 tokens/s, Drafted throughput: 7.80 tokens/s, Accepted: 52 tokens, Drafted: 78 tokens, Per-position acceptance rate: 0.846, 0.654, 0.500, Avg Draft acceptance rate: 66.7%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:54 [loggers.py:257] Engine 000: Avg prompt throughput: 498.0 tokens/s, Avg generation throughput: 325.6 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:08:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.78, Accepted throughput: 207.38 tokens/s, Drafted throughput: 348.86 tokens/s, Accepted: 2074 tokens, Drafted: 3489 tokens, Per-position acceptance rate: 0.742, 0.571, 0.470, Avg Draft acceptance rate: 59.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:04 [loggers.py:257] Engine 000: Avg prompt throughput: 814.6 tokens/s, Avg generation throughput: 653.7 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.87, Accepted throughput: 425.55 tokens/s, Drafted throughput: 681.52 tokens/s, Accepted: 4256 tokens, Drafted: 6816 tokens, Per-position acceptance rate: 0.773, 0.618, 0.482, Avg Draft acceptance rate: 62.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:14 [loggers.py:257] Engine 000: Avg prompt throughput: 712.3 tokens/s, Avg generation throughput: 632.5 tokens/s, Running: 15 reqs, Waiting: 0 reqs, GPU KV cache usage: 38.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.71, Accepted throughput: 399.38 tokens/s, Drafted throughput: 698.97 tokens/s, Accepted: 3994 tokens, Drafted: 6990 tokens, Per-position acceptance rate: 0.727, 0.560, 0.427, Avg Draft acceptance rate: 57.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:24 [loggers.py:257] Engine 000: Avg prompt throughput: 827.9 tokens/s, Avg generation throughput: 666.2 tokens/s, Running: 11 reqs, Waiting: 0 reqs, GPU KV cache usage: 29.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.00, Accepted throughput: 443.48 tokens/s, Drafted throughput: 666.28 tokens/s, Accepted: 4435 tokens, Drafted: 6663 tokens, Per-position acceptance rate: 0.799, 0.661, 0.537, Avg Draft acceptance rate: 66.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:34 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 71.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.70, Accepted throughput: 45.50 tokens/s, Drafted throughput: 80.10 tokens/s, Accepted: 455 tokens, Drafted: 801 tokens, Per-position acceptance rate: 0.727, 0.551, 0.427, Avg Draft acceptance rate: 56.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:44 [loggers.py:257] Engine 000: Avg prompt throughput: 689.8 tokens/s, Avg generation throughput: 366.7 tokens/s, Running: 32 reqs, Waiting: 0 reqs, GPU KV cache usage: 69.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.83, Accepted throughput: 235.06 tokens/s, Drafted throughput: 384.83 tokens/s, Accepted: 2351 tokens, Drafted: 3849 tokens, Per-position acceptance rate: 0.749, 0.593, 0.490, Avg Draft acceptance rate: 61.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1253.1 tokens/s, Avg generation throughput: 969.5 tokens/s, Running: 31 reqs, Waiting: 0 reqs, GPU KV cache usage: 67.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:09:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 624.41 tokens/s, Drafted throughput: 1030.22 tokens/s, Accepted: 6244 tokens, Drafted: 10302 tokens, Per-position acceptance rate: 0.756, 0.599, 0.463, Avg Draft acceptance rate: 60.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1229.1 tokens/s, Avg generation throughput: 1005.5 tokens/s, Running: 30 reqs, Waiting: 0 reqs, GPU KV cache usage: 63.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.89, Accepted throughput: 657.31 tokens/s, Drafted throughput: 1041.46 tokens/s, Accepted: 6574 tokens, Drafted: 10416 tokens, Per-position acceptance rate: 0.774, 0.620, 0.499, Avg Draft acceptance rate: 63.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:14 [loggers.py:257] Engine 000: Avg prompt throughput: 1194.2 tokens/s, Avg generation throughput: 991.7 tokens/s, Running: 30 reqs, Waiting: 0 reqs, GPU KV cache usage: 63.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 639.68 tokens/s, Drafted throughput: 1052.07 tokens/s, Accepted: 6397 tokens, Drafted: 10521 tokens, Per-position acceptance rate: 0.751, 0.600, 0.473, Avg Draft acceptance rate: 60.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1150.6 tokens/s, Avg generation throughput: 1005.8 tokens/s, Running: 30 reqs, Waiting: 0 reqs, GPU KV cache usage: 63.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.89, Accepted throughput: 658.87 tokens/s, Drafted throughput: 1043.65 tokens/s, Accepted: 6589 tokens, Drafted: 10437 tokens, Per-position acceptance rate: 0.771, 0.624, 0.499, Avg Draft acceptance rate: 63.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:34 [loggers.py:257] Engine 000: Avg prompt throughput: 135.3 tokens/s, Avg generation throughput: 378.9 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.75, Accepted throughput: 242.88 tokens/s, Drafted throughput: 416.66 tokens/s, Accepted: 2429 tokens, Drafted: 4167 tokens, Per-position acceptance rate: 0.739, 0.567, 0.443, Avg Draft acceptance rate: 58.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:44 [loggers.py:257] Engine 000: Avg prompt throughput: 551.7 tokens/s, Avg generation throughput: 33.5 tokens/s, Running: 64 reqs, Waiting: 0 reqs, GPU KV cache usage: 88.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 3.10, Accepted throughput: 20.60 tokens/s, Drafted throughput: 29.40 tokens/s, Accepted: 206 tokens, Drafted: 294 tokens, Per-position acceptance rate: 0.806, 0.714, 0.582, Avg Draft acceptance rate: 70.1%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1347.3 tokens/s, Avg generation throughput: 1064.3 tokens/s, Running: 50 reqs, Waiting: 12 reqs, GPU KV cache usage: 97.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:10:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 685.18 tokens/s, Drafted throughput: 1118.67 tokens/s, Accepted: 6852 tokens, Drafted: 11187 tokens, Per-position acceptance rate: 0.762, 0.600, 0.475, Avg Draft acceptance rate: 61.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1225.8 tokens/s, Avg generation throughput: 1025.0 tokens/s, Running: 46 reqs, Waiting: 13 reqs, GPU KV cache usage: 93.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 660.70 tokens/s, Drafted throughput: 1086.90 tokens/s, Accepted: 6607 tokens, Drafted: 10869 tokens, Per-position acceptance rate: 0.750, 0.601, 0.473, Avg Draft acceptance rate: 60.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:14 [loggers.py:257] Engine 000: Avg prompt throughput: 1198.7 tokens/s, Avg generation throughput: 1055.3 tokens/s, Running: 45 reqs, Waiting: 15 reqs, GPU KV cache usage: 96.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 681.65 tokens/s, Drafted throughput: 1111.71 tokens/s, Accepted: 6817 tokens, Drafted: 11118 tokens, Per-position acceptance rate: 0.756, 0.606, 0.478, Avg Draft acceptance rate: 61.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1173.4 tokens/s, Avg generation throughput: 1095.0 tokens/s, Running: 43 reqs, Waiting: 19 reqs, GPU KV cache usage: 98.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.90, Accepted throughput: 716.36 tokens/s, Drafted throughput: 1129.58 tokens/s, Accepted: 7165 tokens, Drafted: 11298 tokens, Per-position acceptance rate: 0.773, 0.627, 0.502, Avg Draft acceptance rate: 63.4%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:34 [loggers.py:257] Engine 000: Avg prompt throughput: 1356.1 tokens/s, Avg generation throughput: 1014.1 tokens/s, Running: 48 reqs, Waiting: 15 reqs, GPU KV cache usage: 97.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.82, Accepted throughput: 652.85 tokens/s, Drafted throughput: 1074.22 tokens/s, Accepted: 6529 tokens, Drafted: 10743 tokens, Per-position acceptance rate: 0.760, 0.595, 0.469, Avg Draft acceptance rate: 60.8%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1137.4 tokens/s, Avg generation throughput: 1078.2 tokens/s, Running: 44 reqs, Waiting: 18 reqs, GPU KV cache usage: 94.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.84, Accepted throughput: 696.26 tokens/s, Drafted throughput: 1135.44 tokens/s, Accepted: 6963 tokens, Drafted: 11355 tokens, Per-position acceptance rate: 0.761, 0.597, 0.481, Avg Draft acceptance rate: 61.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1334.8 tokens/s, Avg generation throughput: 1055.4 tokens/s, Running: 52 reqs, Waiting: 9 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:11:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.85, Accepted throughput: 681.79 tokens/s, Drafted throughput: 1107.12 tokens/s, Accepted: 6819 tokens, Drafted: 11073 tokens, Per-position acceptance rate: 0.765, 0.603, 0.480, Avg Draft acceptance rate: 61.6%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:12:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1150.7 tokens/s, Avg generation throughput: 1022.9 tokens/s, Running: 42 reqs, Waiting: 21 reqs, GPU KV cache usage: 96.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:12:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.72, Accepted throughput: 644.75 tokens/s, Drafted throughput: 1126.42 tokens/s, Accepted: 6448 tokens, Drafted: 11265 tokens, Per-position acceptance rate: 0.729, 0.556, 0.432, Avg Draft acceptance rate: 57.2%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:12:14 [loggers.py:257] Engine 000: Avg prompt throughput: 665.8 tokens/s, Avg generation throughput: 890.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:12:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.78, Accepted throughput: 572.68 tokens/s, Drafted throughput: 965.67 tokens/s, Accepted: 5727 tokens, Drafted: 9657 tokens, Per-position acceptance rate: 0.734, 0.582, 0.463, Avg Draft acceptance rate: 59.3%
[0;36m(APIServer pid=52260)[0;0m INFO 01-27 15:12:24 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
