{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values from Verda differ from the ones of the LRZ benchmark. Not entirely sure why.\n",
    "# Verda\n",
    "tpot_1_7b = 2.27\n",
    "tpot_32b = 23.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7593ee",
   "metadata": {},
   "source": [
    "What kind of speedups should be obvserve from SD?\n",
    "For $K=4$, we execute the drafter 4 times, and the target 1 time.\n",
    "And because of token rejections, we get a number of token equivalent to the acceptance length (AL)\n",
    "\n",
    "$$T_{s} = \\frac{K \\cdot T_{d} + T_{t}}{AL} = \\frac{ITL}{AL} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "expected_sd_itl = k * tpot_1_7b + tpot_32b\n",
    "al = 3.28\n",
    "expected_sd_tpot = expected_sd_itl / al\n",
    "expected_sd_tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86bada1",
   "metadata": {},
   "source": [
    "However, we are observing higher (worse, slower) TPOT. How slow is then the drafter really running?\n",
    "\n",
    "\n",
    "$$T_{d} = \\frac{T_{s} \\cdot AL - T_{t}}{K}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sd_tpot = 10.46\n",
    "implied_tpot_1_7b = (actual_sd_tpot * al - tpot_32b) / k\n",
    "implied_tpot_1_7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "implied_itl = 4 * implied_tpot_1_7b + tpot_32b\n",
    "implied_itl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c9f69",
   "metadata": {},
   "source": [
    "The implied SD ITL is equal to the actual SD ITL (34.34), meaning that we are correct in assuming that the TPOT of the target is unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60a89d",
   "metadata": {},
   "source": [
    "What are the current speedups?\n",
    "We compare TPOT in SD to non-SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_speedup = tpot_32b / actual_sd_tpot\n",
    "actual_speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0bb8ac",
   "metadata": {},
   "source": [
    "What should be the speedup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_speedup = tpot_32b / expected_sd_tpot\n",
    "expected_speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3fae4",
   "metadata": {},
   "source": [
    "Would K=4 still be optimal?\n",
    "The analysis below show that the optimal K (to maximize TPOT) should be 5 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced93e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# from k=3 to k=8\n",
    "k1 = 1.80\n",
    "k2 = 2.40\n",
    "k3 = 2.87\n",
    "k4 = 3.28\n",
    "k5 = 3.53\n",
    "k6 = 3.70\n",
    "k7 = 3.90\n",
    "k8 = 4.04\n",
    "acceptance_lens = torch.tensor([k1, k2, k3, k4, k5, k6, k7, k8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def sd_tpot(k, tpot_1_7b):\n",
    "    itl = tpot_1_7b * k + tpot_32b\n",
    "    # starts at k=1, so k=1 -> idx=0\n",
    "    al = acceptance_lens[idx := k - 1]\n",
    "    return itl / al\n",
    "\n",
    "\n",
    "sd_tpot(4, tpot_1_7b=tpot_1_7b), torch.tensor(expected_sd_tpot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20158c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "k_values = torch.arange(1, 9)\n",
    "expected_tpot_values = torch.tensor([sd_tpot(k, tpot_1_7b=tpot_1_7b) for k in k_values])\n",
    "actual_tpot_values = torch.tensor(\n",
    "    [sd_tpot(k, tpot_1_7b=implied_tpot_1_7b) for k in k_values]\n",
    ")\n",
    "\n",
    "plt.plot(k_values, expected_tpot_values, label=\"Expected\", marker=\"o\")\n",
    "plt.plot(\n",
    "    k_values[expected_tpot_values.argmin()],\n",
    "    expected_tpot_values.min(),\n",
    "    marker=\"x\",\n",
    "    color=\"blue\",\n",
    "    markersize=15,\n",
    ")\n",
    "plt.plot(k_values, actual_tpot_values, label=\"Current\", marker=\"o\")\n",
    "plt.plot(\n",
    "    k_values[actual_tpot_values.argmin()],\n",
    "    actual_tpot_values.min(),\n",
    "    marker=\"x\",\n",
    "    color=\"red\",\n",
    "    markersize=15,\n",
    ")\n",
    "plt.xlabel(\"Number of Speculative Tokens (K)\")\n",
    "plt.ylabel(\"SD TPOT (ms)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(alpha=0.5)\n",
    "plt.legend()\n",
    "\n",
    "os.makedirs(\"imgs\", exist_ok=True)\n",
    "plt.savefig(\"imgs/tpot_k_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_expected_tpot_sd = expected_tpot_values.min()\n",
    "best_expected_speedup = tpot_32b / best_expected_tpot_sd\n",
    "best_expected_speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_expected_speedup / actual_speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "implied_tpot_1_7b / tpot_1_7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ed2a2",
   "metadata": {},
   "source": [
    "* The draft model (Qwen3-1.7B) runs decodes faster when its the main model (TPOT of 2.27ms vs 2.66ms).\n",
    "* Implementing full CUDA graphs for the draft model would speed up this drafter by 17%.\n",
    "* However, since the drafter only makes a fraction of the total runtime, the TPOT improvement would be closer to 5 to 6%.\n",
    "* Given the lower overhead, the optimal $K$ would move from 4 to 5, though the difference is small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
