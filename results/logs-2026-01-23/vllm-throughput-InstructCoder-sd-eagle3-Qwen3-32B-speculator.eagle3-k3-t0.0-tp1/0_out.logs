Removing any existing container named vllm-throughput-InstructCoder-sd-eagle3-Qwen3-32B-speculator.eagle3-k3-t0.0-tp1...
Creating new container vllm-throughput-InstructCoder-sd-eagle3-Qwen3-32B-speculator.eagle3-k3-t0.0-tp1...
code
datasets

==========
== CUDA ==
==========

CUDA Version 12.4.0

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

Starting vLLM server...
Server started with PID: 3300916
Starting benchmark with MAX_CONCURRENCY = 1 and NUM_PROMPTS = 50...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:18:58 [api_server.py:872] vLLM API server version 0.1.dev13107+ge1a34c3a5
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:18:58 [utils.py:267] non-default args: {'model_tag': 'Qwen/Qwen3-32B', 'port': 15027, 'disable_uvicorn_access_log': True, 'model': 'Qwen/Qwen3-32B', 'max_model_len': 5000, 'enable_prefix_caching': False, 'speculative_config': {'method': 'eagle3', 'model': 'RedHatAI/Qwen3-32B-speculator.eagle3', 'num_speculative_tokens': 3, 'max_model_len': 5000}}
[0;36m(APIServer pid=3300916)[0;0m WARNING 01-23 00:18:58 [system_utils.py:262] Found ulimit of 51200 and failed to automatically increase with error current limit exceeds maximum limit. This can cause fd limit errors like `OSError: [Errno 24] Too many open files`. Consider increasing with ulimit -n
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:18:59 [model.py:541] Resolved architecture: Qwen3ForCausalLM
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:18:59 [model.py:1559] Using max model len 5000
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:19:01 [model.py:541] Resolved architecture: Eagle3LlamaForCausalLM
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:19:01 [model.py:1559] Using max model len 40960
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:19:01 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=8192.
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:19:01 [vllm.py:618] Asynchronous scheduling is enabled.
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:19:01 [vllm.py:625] Disabling NCCL for DP synchronization when using async scheduling.
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f9ebf8c2fc0>, seed=0, num_prompts=50, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=1, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=1.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-51ad6f0d-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
WARNING 01-23 00:19:06 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:11 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:19:13 [core.py:96] Initializing a V1 LLM engine (v0.1.dev13107+ge1a34c3a5) with config: model='Qwen/Qwen3-32B', speculative_config=SpeculativeConfig(method='eagle3', model='RedHatAI/Qwen3-32B-speculator.eagle3', num_spec_tokens=3), tokenizer='Qwen/Qwen3-32B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=Qwen/Qwen3-32B, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:19:15 [parallel_state.py:1212] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.195.244.45:35591 backend=nccl
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:19:15 [parallel_state.py:1423] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank N/A
WARNING 01-23 00:19:16 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m WARNING 01-23 00:19:19 [__init__.py:204] min_p, logit_bias, and min_tokens parameters won't currently work with speculative decoding enabled.
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:19:19 [gpu_model_runner.py:3824] Starting to load model Qwen/Qwen3-32B...
WARNING 01-23 00:19:21 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:19:22 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')
WARNING 01-23 00:19:26 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:31 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:36 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:41 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:46 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:51 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:19:56 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:01 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:06 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:11 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:16 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:21 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:26 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:31 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:36 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:41 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:46 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:51 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:20:56 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:01 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:06 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:11 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:16 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:21 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:26 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:31 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:32 [default_loader.py:291] Loading weights took 128.69 seconds
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:32 [gpu_model_runner.py:3851] Loading drafter model...
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:33 [weight_utils.py:550] No model.safetensors.index.json found in remote.
WARNING 01-23 00:21:36 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:39 [default_loader.py:291] Loading weights took 6.33 seconds
WARNING 01-23 00:21:41 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:41 [eagle.py:1146] Detected EAGLE model with distinct embed_tokens weights. Keeping separate embedding weights from the target model.
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:43 [eagle.py:1195] Detected EAGLE model with distinct lm_head weights. Keeping separate lm_head weights from the target model.
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:21:43 [gpu_model_runner.py:3921] Model loading took 63.94 GiB memory and 143.108194 seconds
WARNING 01-23 00:21:46 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:51 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:21:56 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:22:01 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:03 [backends.py:644] Using cache directory: /dss/dssfs02/lwp-dss-0001/pn76je/pn76je-dss-0000/.cache/vllm/torch_compile_cache/a2a295eb88/rank_0_0/backbone for vLLM's torch.compile
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:03 [backends.py:704] Dynamo bytecode transform time: 19.28 s
WARNING 01-23 00:22:06 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:22:11 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:22:16 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:22:21 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:22 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 8192) from the cache, took 6.202 s
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:22 [monitor.py:34] torch.compile takes 25.49 s in total
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:23 [backends.py:644] Using cache directory: /dss/dssfs02/lwp-dss-0001/pn76je/pn76je-dss-0000/.cache/vllm/torch_compile_cache/a2a295eb88/rank_0_0/eagle_head for vLLM's torch.compile
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:23 [backends.py:704] Dynamo bytecode transform time: 0.53 s
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:23 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 8192) from the cache, took 0.125 s
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:23 [monitor.py:34] torch.compile takes 26.14 s in total
WARNING 01-23 00:22:26 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:26 [gpu_worker.py:355] Available KV cache memory: 11.72 GiB
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:26 [kv_cache_utils.py:1307] GPU KV cache size: 47,264 tokens
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:26 [kv_cache_utils.py:1312] Maximum concurrency for 5,000 tokens per request: 9.44x
WARNING 01-23 00:22:31 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
WARNING 01-23 00:22:36 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:38 [gpu_model_runner.py:4880] Graph capturing finished in 11 secs, took -0.63 GiB
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:38 [core.py:272] init engine (profile, create kv cache, warmup model) took 54.27 seconds
[0;36m(EngineCore_DP0 pid=3305804)[0;0m INFO 01-23 00:22:39 [vllm.py:618] Asynchronous scheduling is enabled.
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:40 [api_server.py:663] Supported tasks: ['generate']
[0;36m(APIServer pid=3300916)[0;0m WARNING 01-23 00:22:40 [model.py:1372] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:40 [serving.py:227] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:40 [serving.py:149] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:40 [serving.py:185] Warming up chat template processing...
WARNING 01-23 00:22:41 [ready_checker.py:69] Endpoint is not ready. Error=''Traceback (most recent call last):\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection\n    sock = await aiohappyeyeballs.start_connection(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 122, in start_connection\n    raise first_exception\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 73, in start_connection\n    sock = await _connect_sock(\n           ^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 208, in _connect_sock\n    await loop.sock_connect(sock, address)\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 638, in sock_connect\n    return await fut\n           ^^^^^^^^^\n  File "/opt/conda/lib/python3.11/asyncio/selector_events.py", line 678, in _sock_connect_cb\n    raise OSError(err, f\'Connect call failed {address}\')\nConnectionRefusedError: [Errno 111] Connect call failed (\'127.0.0.1\', 15027)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File "/workspace/code/vllm/vllm/benchmarks/lib/endpoint_request_func.py", line 187, in async_request_openai_completions\n    async with session.post(url=api_url, json=payload, headers=headers) as response:\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__\n    self._resp: _RetType = await self._coro\n                           ^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request\n    resp = await handler(req)\n           ^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request\n    conn = await self._connector.connect(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect\n    proto = await self._create_connection(req, traces, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection\n    _, proto = await self._create_direct_connection(req, traces, timeout)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection\n    raise last_exc\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection\n    transp, proto = await self._wrap_create_connection(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/root/ptvenv/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection\n    raise client_error(req.connection_key, exc) from exc\naiohttp.client_exceptions.ClientConnectorError: Cannot connect to host 127.0.0.1:15027 ssl:default [Connect call failed (\'127.0.0.1\', 15027)]\n''
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:42 [chat_utils.py:599] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:42 [serving.py:221] Chat template warmup completed in 1947.1ms
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [serving.py:80] Using default completion sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [serving.py:149] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [api_server.py:946] Starting vLLM API server 0 on http://0.0.0.0:15027
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:38] Available routes are:
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /openapi.json, Methods: HEAD, GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /docs, Methods: HEAD, GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /redoc, Methods: HEAD, GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /scale_elastic_ep, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /tokenize, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /detokenize, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /inference/v1/generate, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /pause, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /resume, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /is_paused, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /metrics, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /health, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/chat/completions, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/chat/completions/render, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/responses, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/audio/translations, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/completions, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/completions/render, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/messages, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/models, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /load, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /version, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /ping, Methods: GET
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /ping, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /invocations, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /classify, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/embeddings, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /score, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/score, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /rerank, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v1/rerank, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /v2/rerank, Methods: POST
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:43 [launcher.py:46] Route: /pooling, Methods: POST
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 1.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 1
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:53 [loggers.py:257] Engine 000: Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 24.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:22:53 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 13.40 tokens/s, Drafted throughput: 34.18 tokens/s, Accepted: 187 tokens, Drafted: 477 tokens, Per-position acceptance rate: 0.629, 0.371, 0.176, Avg Draft acceptance rate: 39.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:03 [loggers.py:257] Engine 000: Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 58.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:03 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.24, Accepted throughput: 32.60 tokens/s, Drafted throughput: 78.89 tokens/s, Accepted: 326 tokens, Drafted: 789 tokens, Per-position acceptance rate: 0.662, 0.384, 0.194, Avg Draft acceptance rate: 41.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:13 [loggers.py:257] Engine 000: Avg prompt throughput: 45.5 tokens/s, Avg generation throughput: 59.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:13 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.26, Accepted throughput: 33.00 tokens/s, Drafted throughput: 78.60 tokens/s, Accepted: 330 tokens, Drafted: 786 tokens, Per-position acceptance rate: 0.683, 0.374, 0.202, Avg Draft acceptance rate: 42.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:23 [loggers.py:257] Engine 000: Avg prompt throughput: 32.1 tokens/s, Avg generation throughput: 55.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:23 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.10, Accepted throughput: 28.70 tokens/s, Drafted throughput: 78.29 tokens/s, Accepted: 287 tokens, Drafted: 783 tokens, Per-position acceptance rate: 0.609, 0.318, 0.172, Avg Draft acceptance rate: 36.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:33 [loggers.py:257] Engine 000: Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 57.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:33 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 30.59 tokens/s, Drafted throughput: 78.89 tokens/s, Accepted: 306 tokens, Drafted: 789 tokens, Per-position acceptance rate: 0.616, 0.357, 0.190, Avg Draft acceptance rate: 38.8%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:43 [loggers.py:257] Engine 000: Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 58.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:43 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.24, Accepted throughput: 32.50 tokens/s, Drafted throughput: 78.59 tokens/s, Accepted: 325 tokens, Drafted: 786 tokens, Per-position acceptance rate: 0.634, 0.378, 0.229, Avg Draft acceptance rate: 41.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:53 [loggers.py:257] Engine 000: Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 54.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:23:53 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.07, Accepted throughput: 28.20 tokens/s, Drafted throughput: 78.90 tokens/s, Accepted: 282 tokens, Drafted: 789 tokens, Per-position acceptance rate: 0.605, 0.323, 0.144, Avg Draft acceptance rate: 35.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:03 [loggers.py:257] Engine 000: Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 59.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:03 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.26, Accepted throughput: 33.10 tokens/s, Drafted throughput: 78.59 tokens/s, Accepted: 331 tokens, Drafted: 786 tokens, Per-position acceptance rate: 0.706, 0.370, 0.187, Avg Draft acceptance rate: 42.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:13 [loggers.py:257] Engine 000: Avg prompt throughput: 42.8 tokens/s, Avg generation throughput: 57.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:13 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 31.00 tokens/s, Drafted throughput: 79.19 tokens/s, Accepted: 310 tokens, Drafted: 792 tokens, Per-position acceptance rate: 0.640, 0.333, 0.201, Avg Draft acceptance rate: 39.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:23 [loggers.py:257] Engine 000: Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 55.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:23 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.08, Accepted throughput: 28.50 tokens/s, Drafted throughput: 79.19 tokens/s, Accepted: 285 tokens, Drafted: 792 tokens, Per-position acceptance rate: 0.583, 0.318, 0.178, Avg Draft acceptance rate: 36.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:33 [loggers.py:257] Engine 000: Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 58.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:33 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.23, Accepted throughput: 32.20 tokens/s, Drafted throughput: 78.59 tokens/s, Accepted: 322 tokens, Drafted: 786 tokens, Per-position acceptance rate: 0.660, 0.378, 0.191, Avg Draft acceptance rate: 41.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:43 [loggers.py:257] Engine 000: Avg prompt throughput: 44.1 tokens/s, Avg generation throughput: 57.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:43 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 31.10 tokens/s, Drafted throughput: 79.19 tokens/s, Accepted: 311 tokens, Drafted: 792 tokens, Per-position acceptance rate: 0.655, 0.345, 0.178, Avg Draft acceptance rate: 39.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:53 [loggers.py:257] Engine 000: Avg prompt throughput: 44.6 tokens/s, Avg generation throughput: 56.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:24:53 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.15, Accepted throughput: 30.20 tokens/s, Drafted throughput: 78.59 tokens/s, Accepted: 302 tokens, Drafted: 786 tokens, Per-position acceptance rate: 0.626, 0.347, 0.179, Avg Draft acceptance rate: 38.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:03 [loggers.py:257] Engine 000: Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 56.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:03 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.13, Accepted throughput: 29.90 tokens/s, Drafted throughput: 79.50 tokens/s, Accepted: 299 tokens, Drafted: 795 tokens, Per-position acceptance rate: 0.615, 0.343, 0.170, Avg Draft acceptance rate: 37.6%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:13 [loggers.py:257] Engine 000: Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 59.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:13 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.29, Accepted throughput: 33.70 tokens/s, Drafted throughput: 78.29 tokens/s, Accepted: 337 tokens, Drafted: 783 tokens, Per-position acceptance rate: 0.651, 0.425, 0.215, Avg Draft acceptance rate: 43.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:23 [loggers.py:257] Engine 000: Avg prompt throughput: 35.4 tokens/s, Avg generation throughput: 52.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:23 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.00, Accepted throughput: 26.20 tokens/s, Drafted throughput: 78.29 tokens/s, Accepted: 262 tokens, Drafted: 783 tokens, Per-position acceptance rate: 0.571, 0.310, 0.123, Avg Draft acceptance rate: 33.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:33 [loggers.py:257] Engine 000: Avg prompt throughput: 48.4 tokens/s, Avg generation throughput: 59.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:33 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.27, Accepted throughput: 33.30 tokens/s, Drafted throughput: 78.90 tokens/s, Accepted: 333 tokens, Drafted: 789 tokens, Per-position acceptance rate: 0.658, 0.392, 0.217, Avg Draft acceptance rate: 42.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:43 [loggers.py:257] Engine 000: Avg prompt throughput: 33.8 tokens/s, Avg generation throughput: 60.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:43 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.28, Accepted throughput: 33.50 tokens/s, Drafted throughput: 78.59 tokens/s, Accepted: 335 tokens, Drafted: 786 tokens, Per-position acceptance rate: 0.664, 0.405, 0.210, Avg Draft acceptance rate: 42.6%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     50        
Failed requests:                         0         
Maximum request concurrency:             1         
Request rate configured (RPS):           1.00      
Benchmark duration (s):                  175.11    
Total input tokens:                      7227      
Total generated tokens:                  10000     
Request throughput (req/s):              0.29      
Output token throughput (tok/s):         57.11     
Peak output token throughput (tok/s):    27.00     
Peak concurrent requests:                2.00      
Total token throughput (tok/s):          98.38     
---------------Time to First Token----------------
Mean TTFT (ms):                          67.69     
Median TTFT (ms):                        77.93     
P99 TTFT (ms):                           85.80     
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          17.18     
Median TPOT (ms):                        17.16     
P99 TPOT (ms):                           19.73     
---------------Inter-token Latency----------------
Mean ITL (ms):                           37.34     
Median ITL (ms):                         37.35     
P99 ITL (ms):                            37.72     
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.38     
Acceptance length:                       2.18      
Drafts:                                  4578      
Draft tokens:                            13734     
Accepted tokens:                         5408      
Per-position acceptance (%):
  Position 0:                            63.70     
  Position 1:                            35.82     
  Position 2:                            18.61     
==================================================
Starting benchmark with MAX_CONCURRENCY = 2 and NUM_PROMPTS = 50...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:53 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.3 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:25:53 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.09, Accepted throughput: 4.90 tokens/s, Drafted throughput: 13.50 tokens/s, Accepted: 49 tokens, Drafted: 135 tokens, Per-position acceptance rate: 0.622, 0.311, 0.156, Avg Draft acceptance rate: 36.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:03 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f44f53defc0>, seed=0, num_prompts=50, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=2, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=2.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-3ea2ee8b-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:13 [loggers.py:257] Engine 000: Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 13.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:13 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.11, Accepted throughput: 3.55 tokens/s, Drafted throughput: 9.60 tokens/s, Accepted: 71 tokens, Drafted: 192 tokens, Per-position acceptance rate: 0.609, 0.359, 0.141, Avg Draft acceptance rate: 37.0%
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 2.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 2
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:23 [loggers.py:257] Engine 000: Avg prompt throughput: 92.6 tokens/s, Avg generation throughput: 101.3 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:23 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.26, Accepted throughput: 56.39 tokens/s, Drafted throughput: 134.09 tokens/s, Accepted: 564 tokens, Drafted: 1341 tokens, Per-position acceptance rate: 0.682, 0.374, 0.206, Avg Draft acceptance rate: 42.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:34 [loggers.py:257] Engine 000: Avg prompt throughput: 74.9 tokens/s, Avg generation throughput: 112.7 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 60.89 tokens/s, Drafted throughput: 154.17 tokens/s, Accepted: 609 tokens, Drafted: 1542 tokens, Per-position acceptance rate: 0.630, 0.354, 0.200, Avg Draft acceptance rate: 39.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:44 [loggers.py:257] Engine 000: Avg prompt throughput: 73.2 tokens/s, Avg generation throughput: 113.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.19, Accepted throughput: 61.49 tokens/s, Drafted throughput: 155.09 tokens/s, Accepted: 615 tokens, Drafted: 1551 tokens, Per-position acceptance rate: 0.648, 0.364, 0.178, Avg Draft acceptance rate: 39.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:54 [loggers.py:257] Engine 000: Avg prompt throughput: 77.1 tokens/s, Avg generation throughput: 115.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:26:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.23, Accepted throughput: 63.40 tokens/s, Drafted throughput: 154.49 tokens/s, Accepted: 634 tokens, Drafted: 1545 tokens, Per-position acceptance rate: 0.658, 0.377, 0.196, Avg Draft acceptance rate: 41.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:04 [loggers.py:257] Engine 000: Avg prompt throughput: 86.4 tokens/s, Avg generation throughput: 108.2 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.10, Accepted throughput: 56.39 tokens/s, Drafted throughput: 154.18 tokens/s, Accepted: 564 tokens, Drafted: 1542 tokens, Per-position acceptance rate: 0.613, 0.323, 0.161, Avg Draft acceptance rate: 36.6%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:14 [loggers.py:257] Engine 000: Avg prompt throughput: 105.3 tokens/s, Avg generation throughput: 113.1 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.21, Accepted throughput: 62.00 tokens/s, Drafted throughput: 153.59 tokens/s, Accepted: 620 tokens, Drafted: 1536 tokens, Per-position acceptance rate: 0.658, 0.373, 0.180, Avg Draft acceptance rate: 40.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:24 [loggers.py:257] Engine 000: Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 107.6 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.10, Accepted throughput: 56.30 tokens/s, Drafted throughput: 154.20 tokens/s, Accepted: 563 tokens, Drafted: 1542 tokens, Per-position acceptance rate: 0.595, 0.337, 0.163, Avg Draft acceptance rate: 36.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:34 [loggers.py:257] Engine 000: Avg prompt throughput: 44.3 tokens/s, Avg generation throughput: 108.4 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.09, Accepted throughput: 56.50 tokens/s, Drafted throughput: 155.39 tokens/s, Accepted: 565 tokens, Drafted: 1554 tokens, Per-position acceptance rate: 0.587, 0.344, 0.160, Avg Draft acceptance rate: 36.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:44 [loggers.py:257] Engine 000: Avg prompt throughput: 82.2 tokens/s, Avg generation throughput: 114.9 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.23, Accepted throughput: 63.39 tokens/s, Drafted throughput: 154.18 tokens/s, Accepted: 634 tokens, Drafted: 1542 tokens, Per-position acceptance rate: 0.648, 0.381, 0.204, Avg Draft acceptance rate: 41.1%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     50        
Failed requests:                         0         
Maximum request concurrency:             2         
Request rate configured (RPS):           2.00      
Benchmark duration (s):                  90.65     
Total input tokens:                      7227      
Total generated tokens:                  10000     
Request throughput (req/s):              0.55      
Output token throughput (tok/s):         110.31    
Peak output token throughput (tok/s):    54.00     
Peak concurrent requests:                4.00      
Total token throughput (tok/s):          190.04    
---------------Time to First Token----------------
Mean TTFT (ms):                          116.52    
Median TTFT (ms):                        115.62    
P99 TTFT (ms):                           161.98    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          17.38     
Median TPOT (ms):                        17.38     
P99 TPOT (ms):                           20.03     
---------------Inter-token Latency----------------
Mean ITL (ms):                           37.64     
Median ITL (ms):                         37.57     
P99 ITL (ms):                            44.16     
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.13     
Acceptance length:                       2.17      
Drafts:                                  4595      
Draft tokens:                            13785     
Accepted tokens:                         5394      
Per-position acceptance (%):
  Position 0:                            63.46     
  Position 1:                            35.73     
  Position 2:                            18.19     
==================================================
Starting benchmark with MAX_CONCURRENCY = 4 and NUM_PROMPTS = 50...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:54 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:27:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 6.60 tokens/s, Drafted throughput: 16.80 tokens/s, Accepted: 66 tokens, Drafted: 168 tokens, Per-position acceptance rate: 0.661, 0.339, 0.179, Avg Draft acceptance rate: 39.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:04 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f880297efc0>, seed=0, num_prompts=50, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=4, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=4.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-384047bc-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 4.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 4
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:14 [loggers.py:257] Engine 000: Avg prompt throughput: 136.8 tokens/s, Avg generation throughput: 135.9 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.27, Accepted throughput: 37.90 tokens/s, Drafted throughput: 89.69 tokens/s, Accepted: 758 tokens, Drafted: 1794 tokens, Per-position acceptance rate: 0.666, 0.400, 0.202, Avg Draft acceptance rate: 42.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:24 [loggers.py:257] Engine 000: Avg prompt throughput: 165.3 tokens/s, Avg generation throughput: 222.5 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.19, Accepted throughput: 120.88 tokens/s, Drafted throughput: 304.75 tokens/s, Accepted: 1209 tokens, Drafted: 3048 tokens, Per-position acceptance rate: 0.640, 0.357, 0.193, Avg Draft acceptance rate: 39.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:34 [loggers.py:257] Engine 000: Avg prompt throughput: 150.2 tokens/s, Avg generation throughput: 221.7 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 118.79 tokens/s, Drafted throughput: 306.57 tokens/s, Accepted: 1188 tokens, Drafted: 3066 tokens, Per-position acceptance rate: 0.644, 0.339, 0.180, Avg Draft acceptance rate: 38.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:44 [loggers.py:257] Engine 000: Avg prompt throughput: 162.2 tokens/s, Avg generation throughput: 221.4 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 119.29 tokens/s, Drafted throughput: 305.37 tokens/s, Accepted: 1193 tokens, Drafted: 3054 tokens, Per-position acceptance rate: 0.629, 0.359, 0.185, Avg Draft acceptance rate: 39.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:54 [loggers.py:257] Engine 000: Avg prompt throughput: 126.5 tokens/s, Avg generation throughput: 206.0 tokens/s, Running: 2 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:28:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 111.79 tokens/s, Drafted throughput: 283.17 tokens/s, Accepted: 1118 tokens, Drafted: 2832 tokens, Per-position acceptance rate: 0.646, 0.358, 0.180, Avg Draft acceptance rate: 39.5%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     50        
Failed requests:                         0         
Maximum request concurrency:             4         
Request rate configured (RPS):           4.00      
Benchmark duration (s):                  47.20     
Total input tokens:                      7227      
Total generated tokens:                  10000     
Request throughput (req/s):              1.06      
Output token throughput (tok/s):         211.88    
Peak output token throughput (tok/s):    108.00    
Peak concurrent requests:                8.00      
Total token throughput (tok/s):          365.00    
---------------Time to First Token----------------
Mean TTFT (ms):                          115.89    
Median TTFT (ms):                        116.78    
P99 TTFT (ms):                           125.64    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          17.45     
Median TPOT (ms):                        17.39     
P99 TPOT (ms):                           19.98     
---------------Inter-token Latency----------------
Mean ITL (ms):                           38.02     
Median ITL (ms):                         37.89     
P99 ITL (ms):                            47.00     
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.57     
Acceptance length:                       2.19      
Drafts:                                  4567      
Draft tokens:                            13701     
Accepted tokens:                         5422      
Per-position acceptance (%):
  Position 0:                            64.29     
  Position 1:                            35.80     
  Position 2:                            18.63     
==================================================
Starting benchmark with MAX_CONCURRENCY = 8 and NUM_PROMPTS = 80...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:04 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 12.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.14, Accepted throughput: 6.70 tokens/s, Drafted throughput: 17.70 tokens/s, Accepted: 67 tokens, Drafted: 177 tokens, Per-position acceptance rate: 0.644, 0.322, 0.169, Avg Draft acceptance rate: 37.9%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7fd2a2eb2fc0>, seed=0, num_prompts=80, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=8, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=8.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-04f9d458-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:14 [loggers.py:257] Engine 000: Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.38, Accepted throughput: 1.10 tokens/s, Drafted throughput: 2.40 tokens/s, Accepted: 11 tokens, Drafted: 24 tokens, Per-position acceptance rate: 0.750, 0.500, 0.125, Avg Draft acceptance rate: 45.8%
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 8.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 8
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:24 [loggers.py:257] Engine 000: Avg prompt throughput: 215.3 tokens/s, Avg generation throughput: 297.3 tokens/s, Running: 8 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.21, Accepted throughput: 162.60 tokens/s, Drafted throughput: 403.19 tokens/s, Accepted: 1626 tokens, Drafted: 4032 tokens, Per-position acceptance rate: 0.633, 0.372, 0.205, Avg Draft acceptance rate: 40.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:34 [loggers.py:257] Engine 000: Avg prompt throughput: 380.9 tokens/s, Avg generation throughput: 424.2 tokens/s, Running: 8 reqs, Waiting: 0 reqs, GPU KV cache usage: 4.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.15, Accepted throughput: 226.93 tokens/s, Drafted throughput: 589.45 tokens/s, Accepted: 2273 tokens, Drafted: 5904 tokens, Per-position acceptance rate: 0.629, 0.351, 0.175, Avg Draft acceptance rate: 38.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:44 [loggers.py:257] Engine 000: Avg prompt throughput: 270.9 tokens/s, Avg generation throughput: 426.9 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.15, Accepted throughput: 228.20 tokens/s, Drafted throughput: 596.40 tokens/s, Accepted: 2282 tokens, Drafted: 5964 tokens, Per-position acceptance rate: 0.621, 0.347, 0.180, Avg Draft acceptance rate: 38.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:54 [loggers.py:257] Engine 000: Avg prompt throughput: 301.4 tokens/s, Avg generation throughput: 440.5 tokens/s, Running: 7 reqs, Waiting: 0 reqs, GPU KV cache usage: 5.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:29:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.22, Accepted throughput: 242.27 tokens/s, Drafted throughput: 595.11 tokens/s, Accepted: 2423 tokens, Drafted: 5952 tokens, Per-position acceptance rate: 0.640, 0.380, 0.202, Avg Draft acceptance rate: 40.7%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     80        
Failed requests:                         0         
Maximum request concurrency:             8         
Request rate configured (RPS):           8.00      
Benchmark duration (s):                  38.44     
Total input tokens:                      11690     
Total generated tokens:                  16000     
Request throughput (req/s):              2.08      
Output token throughput (tok/s):         416.26    
Peak output token throughput (tok/s):    208.00    
Peak concurrent requests:                15.00     
Total token throughput (tok/s):          720.38    
---------------Time to First Token----------------
Mean TTFT (ms):                          121.83    
Median TTFT (ms):                        121.13    
P99 TTFT (ms):                           135.79    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          18.01     
Median TPOT (ms):                        17.90     
P99 TPOT (ms):                           20.19     
---------------Inter-token Latency----------------
Mean ITL (ms):                           39.06     
Median ITL (ms):                         38.76     
P99 ITL (ms):                            49.72     
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.30     
Acceptance length:                       2.18      
Drafts:                                  7341      
Draft tokens:                            22023     
Accepted tokens:                         8656      
Per-position acceptance (%):
  Position 0:                            62.93     
  Position 1:                            36.13     
  Position 2:                            18.85     
==================================================
Starting benchmark with MAX_CONCURRENCY = 16 and NUM_PROMPTS = 160...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:04 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 28.3 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.09, Accepted throughput: 15.20 tokens/s, Drafted throughput: 41.70 tokens/s, Accepted: 152 tokens, Drafted: 417 tokens, Per-position acceptance rate: 0.576, 0.360, 0.158, Avg Draft acceptance rate: 36.5%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f10c2d4afc0>, seed=0, num_prompts=160, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=16, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=16.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-d0df3b54-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:14 [loggers.py:257] Engine 000: Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 1.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 0.70 tokens/s, Drafted throughput: 1.80 tokens/s, Accepted: 7 tokens, Drafted: 18 tokens, Per-position acceptance rate: 0.667, 0.333, 0.167, Avg Draft acceptance rate: 38.9%
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 16.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 16
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:24 [loggers.py:257] Engine 000: Avg prompt throughput: 468.9 tokens/s, Avg generation throughput: 549.1 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.24, Accepted throughput: 303.27 tokens/s, Drafted throughput: 732.54 tokens/s, Accepted: 3033 tokens, Drafted: 7326 tokens, Per-position acceptance rate: 0.648, 0.391, 0.203, Avg Draft acceptance rate: 41.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:34 [loggers.py:257] Engine 000: Avg prompt throughput: 667.3 tokens/s, Avg generation throughput: 812.1 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 7.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 439.26 tokens/s, Drafted throughput: 1115.31 tokens/s, Accepted: 4393 tokens, Drafted: 11154 tokens, Per-position acceptance rate: 0.633, 0.359, 0.190, Avg Draft acceptance rate: 39.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:44 [loggers.py:257] Engine 000: Avg prompt throughput: 554.4 tokens/s, Avg generation throughput: 820.6 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 10.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.14, Accepted throughput: 437.23 tokens/s, Drafted throughput: 1148.22 tokens/s, Accepted: 4373 tokens, Drafted: 11484 tokens, Per-position acceptance rate: 0.615, 0.348, 0.179, Avg Draft acceptance rate: 38.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:54 [loggers.py:257] Engine 000: Avg prompt throughput: 745.2 tokens/s, Avg generation throughput: 840.6 tokens/s, Running: 16 reqs, Waiting: 0 reqs, GPU KV cache usage: 9.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:30:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.23, Accepted throughput: 463.65 tokens/s, Drafted throughput: 1129.67 tokens/s, Accepted: 4637 tokens, Drafted: 11298 tokens, Per-position acceptance rate: 0.641, 0.378, 0.212, Avg Draft acceptance rate: 41.0%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     160       
Failed requests:                         0         
Maximum request concurrency:             16        
Request rate configured (RPS):           16.00     
Benchmark duration (s):                  40.46     
Total input tokens:                      24361     
Total generated tokens:                  31991     
Request throughput (req/s):              3.95      
Output token throughput (tok/s):         790.61    
Peak output token throughput (tok/s):    400.00    
Peak concurrent requests:                28.00     
Total token throughput (tok/s):          1392.65   
---------------Time to First Token----------------
Mean TTFT (ms):                          132.28    
Median TTFT (ms):                        126.55    
P99 TTFT (ms):                           250.55    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          18.69     
Median TPOT (ms):                        18.62     
P99 TPOT (ms):                           21.86     
---------------Inter-token Latency----------------
Mean ITL (ms):                           40.82     
Median ITL (ms):                         39.95     
P99 ITL (ms):                            51.65     
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.75     
Acceptance length:                       2.19      
Drafts:                                  14576     
Draft tokens:                            43728     
Accepted tokens:                         17381     
Per-position acceptance (%):
  Position 0:                            63.11     
  Position 1:                            36.64     
  Position 2:                            19.50     
==================================================
Starting benchmark with MAX_CONCURRENCY = 32 and NUM_PROMPTS = 320...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:04 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 194.8 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 104.90 tokens/s, Drafted throughput: 271.79 tokens/s, Accepted: 1049 tokens, Drafted: 2718 tokens, Per-position acceptance rate: 0.609, 0.361, 0.188, Avg Draft acceptance rate: 38.6%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:14 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f46564d2fc0>, seed=0, num_prompts=320, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=32, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=32.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-83a917e5-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:24 [loggers.py:257] Engine 000: Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 19.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.21, Accepted throughput: 5.40 tokens/s, Drafted throughput: 13.35 tokens/s, Accepted: 108 tokens, Drafted: 267 tokens, Per-position acceptance rate: 0.640, 0.382, 0.191, Avg Draft acceptance rate: 40.4%
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 32.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 32
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:34 [loggers.py:257] Engine 000: Avg prompt throughput: 1359.4 tokens/s, Avg generation throughput: 1393.1 tokens/s, Running: 30 reqs, Waiting: 0 reqs, GPU KV cache usage: 12.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.19, Accepted throughput: 755.36 tokens/s, Drafted throughput: 1900.39 tokens/s, Accepted: 7554 tokens, Drafted: 19005 tokens, Per-position acceptance rate: 0.633, 0.367, 0.193, Avg Draft acceptance rate: 39.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1076.3 tokens/s, Avg generation throughput: 1516.0 tokens/s, Running: 32 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.19, Accepted throughput: 824.14 tokens/s, Drafted throughput: 2071.70 tokens/s, Accepted: 8243 tokens, Drafted: 20721 tokens, Per-position acceptance rate: 0.630, 0.365, 0.198, Avg Draft acceptance rate: 39.8%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1003.4 tokens/s, Avg generation throughput: 1497.2 tokens/s, Running: 31 reqs, Waiting: 0 reqs, GPU KV cache usage: 19.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:31:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.15, Accepted throughput: 800.24 tokens/s, Drafted throughput: 2086.43 tokens/s, Accepted: 8005 tokens, Drafted: 20871 tokens, Per-position acceptance rate: 0.614, 0.352, 0.184, Avg Draft acceptance rate: 38.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1293.2 tokens/s, Avg generation throughput: 1484.4 tokens/s, Running: 31 reqs, Waiting: 0 reqs, GPU KV cache usage: 16.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 800.01 tokens/s, Drafted throughput: 2055.11 tokens/s, Accepted: 8002 tokens, Drafted: 20556 tokens, Per-position acceptance rate: 0.623, 0.352, 0.192, Avg Draft acceptance rate: 38.9%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     320       
Failed requests:                         0         
Maximum request concurrency:             32        
Request rate configured (RPS):           32.00     
Benchmark duration (s):                  44.51     
Total input tokens:                      48266     
Total generated tokens:                  63960     
Request throughput (req/s):              7.19      
Output token throughput (tok/s):         1437.07   
Peak output token throughput (tok/s):    768.00    
Peak concurrent requests:                51.00     
Total token throughput (tok/s):          2521.53   
---------------Time to First Token----------------
Mean TTFT (ms):                          147.66    
Median TTFT (ms):                        142.53    
P99 TTFT (ms):                           211.42    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          20.66     
Median TPOT (ms):                        20.74     
P99 TPOT (ms):                           24.28     
---------------Inter-token Latency----------------
Mean ITL (ms):                           44.65     
Median ITL (ms):                         42.70     
P99 ITL (ms):                            84.18     
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.04     
Acceptance length:                       2.17      
Drafts:                                  29442     
Draft tokens:                            88326     
Accepted tokens:                         34479     
Per-position acceptance (%):
  Position 0:                            62.36     
  Position 1:                            35.77     
  Position 2:                            18.98     
==================================================
Starting benchmark with MAX_CONCURRENCY = 64 and NUM_PROMPTS = 640...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:14 [loggers.py:257] Engine 000: Avg prompt throughput: 93.2 tokens/s, Avg generation throughput: 504.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.12, Accepted throughput: 267.77 tokens/s, Drafted throughput: 717.51 tokens/s, Accepted: 2678 tokens, Drafted: 7176 tokens, Per-position acceptance rate: 0.612, 0.343, 0.165, Avg Draft acceptance rate: 37.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:24 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f60810dafc0>, seed=0, num_prompts=640, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=64, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=64.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-946db953-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:34 [loggers.py:257] Engine 000: Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 12.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.12, Accepted throughput: 3.25 tokens/s, Drafted throughput: 8.70 tokens/s, Accepted: 65 tokens, Drafted: 174 tokens, Per-position acceptance rate: 0.603, 0.362, 0.155, Avg Draft acceptance rate: 37.4%
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 64.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 64
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1924.6 tokens/s, Avg generation throughput: 1944.3 tokens/s, Running: 64 reqs, Waiting: 0 reqs, GPU KV cache usage: 37.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.21, Accepted throughput: 1062.05 tokens/s, Drafted throughput: 2626.28 tokens/s, Accepted: 10625 tokens, Drafted: 26274 tokens, Per-position acceptance rate: 0.640, 0.372, 0.201, Avg Draft acceptance rate: 40.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1921.7 tokens/s, Avg generation throughput: 2356.5 tokens/s, Running: 64 reqs, Waiting: 0 reqs, GPU KV cache usage: 32.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:32:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 1270.86 tokens/s, Drafted throughput: 3244.19 tokens/s, Accepted: 12711 tokens, Drafted: 32448 tokens, Per-position acceptance rate: 0.625, 0.356, 0.194, Avg Draft acceptance rate: 39.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1810.2 tokens/s, Avg generation throughput: 2390.5 tokens/s, Running: 63 reqs, Waiting: 0 reqs, GPU KV cache usage: 27.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1286.22 tokens/s, Drafted throughput: 3305.84 tokens/s, Accepted: 12864 tokens, Drafted: 33063 tokens, Per-position acceptance rate: 0.626, 0.354, 0.188, Avg Draft acceptance rate: 38.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:14 [loggers.py:257] Engine 000: Avg prompt throughput: 1698.4 tokens/s, Avg generation throughput: 2435.3 tokens/s, Running: 62 reqs, Waiting: 0 reqs, GPU KV cache usage: 31.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1310.57 tokens/s, Drafted throughput: 3371.01 tokens/s, Accepted: 13106 tokens, Drafted: 33711 tokens, Per-position acceptance rate: 0.625, 0.351, 0.190, Avg Draft acceptance rate: 38.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1722.1 tokens/s, Avg generation throughput: 2435.6 tokens/s, Running: 62 reqs, Waiting: 0 reqs, GPU KV cache usage: 34.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1310.11 tokens/s, Drafted throughput: 3369.97 tokens/s, Accepted: 13102 tokens, Drafted: 33702 tokens, Per-position acceptance rate: 0.627, 0.352, 0.187, Avg Draft acceptance rate: 38.9%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     640       
Failed requests:                         0         
Maximum request concurrency:             64        
Request rate configured (RPS):           64.00     
Benchmark duration (s):                  55.50     
Total input tokens:                      94775     
Total generated tokens:                  127975    
Request throughput (req/s):              11.53     
Output token throughput (tok/s):         2306.06   
Peak output token throughput (tok/s):    1344.00   
Peak concurrent requests:                94.00     
Total token throughput (tok/s):          4013.86   
---------------Time to First Token----------------
Mean TTFT (ms):                          228.12    
Median TTFT (ms):                        205.16    
P99 TTFT (ms):                           636.17    
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          25.42     
Median TPOT (ms):                        25.54     
P99 TPOT (ms):                           30.58     
---------------Inter-token Latency----------------
Mean ITL (ms):                           54.97     
Median ITL (ms):                         48.00     
P99 ITL (ms):                            107.94    
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.03     
Acceptance length:                       2.17      
Drafts:                                  58888     
Draft tokens:                            176664    
Accepted tokens:                         68951     
Per-position acceptance (%):
  Position 0:                            62.65     
  Position 1:                            35.44     
  Position 2:                            19.00     
==================================================
Starting benchmark with MAX_CONCURRENCY = 128 and NUM_PROMPTS = 1280...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:34 [loggers.py:257] Engine 000: Avg prompt throughput: 398.5 tokens/s, Avg generation throughput: 1240.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.13, Accepted throughput: 658.85 tokens/s, Drafted throughput: 1756.06 tokens/s, Accepted: 6589 tokens, Drafted: 17562 tokens, Per-position acceptance rate: 0.613, 0.337, 0.176, Avg Draft acceptance rate: 37.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:44 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7f154441afc0>, seed=0, num_prompts=1280, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=128, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=128.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-874b75e3-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 128.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 128
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:54 [loggers.py:257] Engine 000: Avg prompt throughput: 346.9 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 45 reqs, Waiting: 0 reqs, GPU KV cache usage: 15.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:33:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.48, Accepted throughput: 8.85 tokens/s, Drafted throughput: 18.00 tokens/s, Accepted: 177 tokens, Drafted: 360 tokens, Per-position acceptance rate: 0.692, 0.467, 0.317, Avg Draft acceptance rate: 49.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:04 [loggers.py:257] Engine 000: Avg prompt throughput: 2979.6 tokens/s, Avg generation throughput: 2707.6 tokens/s, Running: 116 reqs, Waiting: 0 reqs, GPU KV cache usage: 48.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.21, Accepted throughput: 1473.70 tokens/s, Drafted throughput: 3668.46 tokens/s, Accepted: 14738 tokens, Drafted: 36687 tokens, Per-position acceptance rate: 0.638, 0.367, 0.199, Avg Draft acceptance rate: 40.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:14 [loggers.py:257] Engine 000: Avg prompt throughput: 2402.2 tokens/s, Avg generation throughput: 2970.0 tokens/s, Running: 128 reqs, Waiting: 0 reqs, GPU KV cache usage: 56.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.20, Accepted throughput: 1619.81 tokens/s, Drafted throughput: 4043.84 tokens/s, Accepted: 16212 tokens, Drafted: 40473 tokens, Per-position acceptance rate: 0.634, 0.365, 0.203, Avg Draft acceptance rate: 40.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1871.4 tokens/s, Avg generation throughput: 3121.9 tokens/s, Running: 128 reqs, Waiting: 0 reqs, GPU KV cache usage: 67.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 1680.21 tokens/s, Drafted throughput: 4335.28 tokens/s, Accepted: 16815 tokens, Drafted: 43386 tokens, Per-position acceptance rate: 0.624, 0.353, 0.186, Avg Draft acceptance rate: 38.8%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:34 [loggers.py:257] Engine 000: Avg prompt throughput: 1888.0 tokens/s, Avg generation throughput: 3080.2 tokens/s, Running: 128 reqs, Waiting: 0 reqs, GPU KV cache usage: 79.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1657.70 tokens/s, Drafted throughput: 4259.58 tokens/s, Accepted: 16588 tokens, Drafted: 42624 tokens, Per-position acceptance rate: 0.626, 0.354, 0.188, Avg Draft acceptance rate: 38.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1957.8 tokens/s, Avg generation throughput: 3040.5 tokens/s, Running: 124 reqs, Waiting: 0 reqs, GPU KV cache usage: 78.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 1635.07 tokens/s, Drafted throughput: 4212.21 tokens/s, Accepted: 16351 tokens, Drafted: 42123 tokens, Per-position acceptance rate: 0.621, 0.355, 0.189, Avg Draft acceptance rate: 38.8%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:54 [loggers.py:257] Engine 000: Avg prompt throughput: 2357.2 tokens/s, Avg generation throughput: 2825.9 tokens/s, Running: 122 reqs, Waiting: 0 reqs, GPU KV cache usage: 75.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:34:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 1514.34 tokens/s, Drafted throughput: 3929.24 tokens/s, Accepted: 15144 tokens, Drafted: 39294 tokens, Per-position acceptance rate: 0.618, 0.351, 0.187, Avg Draft acceptance rate: 38.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:04 [loggers.py:257] Engine 000: Avg prompt throughput: 2389.6 tokens/s, Avg generation throughput: 2873.2 tokens/s, Running: 125 reqs, Waiting: 0 reqs, GPU KV cache usage: 65.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1549.98 tokens/s, Drafted throughput: 3960.63 tokens/s, Accepted: 15502 tokens, Drafted: 39612 tokens, Per-position acceptance rate: 0.628, 0.358, 0.188, Avg Draft acceptance rate: 39.1%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:14 [loggers.py:257] Engine 000: Avg prompt throughput: 2373.4 tokens/s, Avg generation throughput: 2885.7 tokens/s, Running: 123 reqs, Waiting: 0 reqs, GPU KV cache usage: 61.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 1561.62 tokens/s, Drafted throughput: 3966.20 tokens/s, Accepted: 15626 tokens, Drafted: 39687 tokens, Per-position acceptance rate: 0.627, 0.362, 0.193, Avg Draft acceptance rate: 39.4%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     1280      
Failed requests:                         0         
Maximum request concurrency:             128       
Request rate configured (RPS):           128.00    
Benchmark duration (s):                  87.79     
Total input tokens:                      189093    
Total generated tokens:                  255960    
Request throughput (req/s):              14.58     
Output token throughput (tok/s):         2915.69   
Peak output token throughput (tok/s):    1920.00   
Peak concurrent requests:                180.00    
Total token throughput (tok/s):          5069.69   
---------------Time to First Token----------------
Mean TTFT (ms):                          419.34    
Median TTFT (ms):                        358.49    
P99 TTFT (ms):                           1451.10   
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          40.82     
Median TPOT (ms):                        41.03     
P99 TPOT (ms):                           50.97     
---------------Inter-token Latency----------------
Mean ITL (ms):                           88.26     
Median ITL (ms):                         71.18     
P99 ITL (ms):                            188.24    
---------------Speculative Decoding---------------
Acceptance rate (%):                     39.05     
Acceptance length:                       2.17      
Drafts:                                  117792    
Draft tokens:                            353376    
Accepted tokens:                         137987    
Per-position acceptance (%):
  Position 0:                            62.53     
  Position 1:                            35.64     
  Position 2:                            18.98     
==================================================
Starting benchmark with MAX_CONCURRENCY = 256 and NUM_PROMPTS = 2560...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:24 [loggers.py:257] Engine 000: Avg prompt throughput: 351.4 tokens/s, Avg generation throughput: 2064.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.12, Accepted throughput: 1094.37 tokens/s, Drafted throughput: 2939.66 tokens/s, Accepted: 10945 tokens, Drafted: 29400 tokens, Per-position acceptance rate: 0.610, 0.337, 0.170, Avg Draft acceptance rate: 37.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:34 [loggers.py:257] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
Namespace(subparser='bench', bench_type='serve', dispatch_function=<function BenchmarkServingSubcommand.cmd at 0x7feda59eafc0>, seed=0, num_prompts=2560, dataset_name='hf', no_stream=False, dataset_path='likaixin/InstructCoder', no_oversample=False, skip_chat_template=False, disable_shuffle=False, custom_output_len=256, spec_bench_output_len=256, spec_bench_category=None, sonnet_input_len=550, sonnet_output_len=150, sonnet_prefix_len=200, sharegpt_output_len=None, blazedit_min_distance=0.0, blazedit_max_distance=1.0, random_input_len=1024, random_output_len=128, random_range_ratio=0.0, random_prefix_len=0, random_batch_size=1, no_reranker=False, random_mm_base_items_per_request=1, random_mm_num_mm_items_range_ratio=0.0, random_mm_limit_mm_per_prompt={'image': 255, 'video': 1}, random_mm_bucket_config={(256, 256, 1): 0.5, (720, 1280, 1): 0.5, (720, 1280, 16): 0.0}, hf_subset=None, hf_split=None, hf_name=None, hf_output_len=None, prefix_repetition_prefix_len=256, prefix_repetition_suffix_len=256, prefix_repetition_num_prefixes=10, prefix_repetition_output_len=128, label=None, backend='openai', base_url=None, host='127.0.0.1', port=15027, endpoint='/v1/completions', header=None, max_concurrency=256, model='Qwen/Qwen3-32B', input_len=None, output_len=None, tokenizer=None, tokenizer_mode='auto', use_beam_search=False, logprobs=None, request_rate=256.0, burstiness=1.0, trust_remote_code=False, disable_tqdm=False, num_warmups=0, profile=False, save_result=False, save_detailed=False, append_result=False, metadata=None, result_dir=None, result_filename=None, ignore_eos=False, percentile_metrics=None, metric_percentiles='99', goodput=None, request_id_prefix='bench-b9a3b69b-', top_p=1.0, top_k=None, min_p=None, temperature=0.0, frequency_penalty=None, presence_penalty=None, repetition_penalty=None, served_model_name=None, lora_modules=None, ramp_up_strategy=None, ramp_up_start_rps=None, ramp_up_end_rps=None, ready_check_timeout_sec=600, extra_body=None)
Starting initial single prompt test run...
Waiting for endpoint to become up in 600 seconds
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:44 [loggers.py:257] Engine 000: Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 7.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.05, Accepted throughput: 2.00 tokens/s, Drafted throughput: 5.70 tokens/s, Accepted: 40 tokens, Drafted: 114 tokens, Per-position acceptance rate: 0.579, 0.316, 0.158, Avg Draft acceptance rate: 35.1%
Initial test run completed.
Starting main benchmark run...
Traffic request rate: 256.0
Burstiness factor: 1.0 (Poisson process)
Maximum request concurrency: 256
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:54 [loggers.py:257] Engine 000: Avg prompt throughput: 3847.1 tokens/s, Avg generation throughput: 1746.0 tokens/s, Running: 195 reqs, Waiting: 61 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:35:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.37, Accepted throughput: 994.57 tokens/s, Drafted throughput: 2178.02 tokens/s, Accepted: 9947 tokens, Drafted: 21783 tokens, Per-position acceptance rate: 0.686, 0.430, 0.254, Avg Draft acceptance rate: 45.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1089.0 tokens/s, Avg generation throughput: 2283.1 tokens/s, Running: 204 reqs, Waiting: 39 reqs, GPU KV cache usage: 96.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.11, Accepted throughput: 1196.01 tokens/s, Drafted throughput: 3239.45 tokens/s, Accepted: 11961 tokens, Drafted: 32397 tokens, Per-position acceptance rate: 0.601, 0.335, 0.171, Avg Draft acceptance rate: 36.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:14 [loggers.py:257] Engine 000: Avg prompt throughput: 1568.8 tokens/s, Avg generation throughput: 3119.2 tokens/s, Running: 169 reqs, Waiting: 75 reqs, GPU KV cache usage: 93.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 1683.93 tokens/s, Drafted throughput: 4298.82 tokens/s, Accepted: 16840 tokens, Drafted: 42990 tokens, Per-position acceptance rate: 0.628, 0.359, 0.188, Avg Draft acceptance rate: 39.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1646.1 tokens/s, Avg generation throughput: 2935.3 tokens/s, Running: 149 reqs, Waiting: 103 reqs, GPU KV cache usage: 97.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.15, Accepted throughput: 1568.02 tokens/s, Drafted throughput: 4090.88 tokens/s, Accepted: 15681 tokens, Drafted: 40911 tokens, Per-position acceptance rate: 0.619, 0.348, 0.183, Avg Draft acceptance rate: 38.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:34 [loggers.py:257] Engine 000: Avg prompt throughput: 2537.7 tokens/s, Avg generation throughput: 2754.5 tokens/s, Running: 163 reqs, Waiting: 91 reqs, GPU KV cache usage: 98.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.19, Accepted throughput: 1492.70 tokens/s, Drafted throughput: 3758.79 tokens/s, Accepted: 14929 tokens, Drafted: 37593 tokens, Per-position acceptance rate: 0.632, 0.364, 0.196, Avg Draft acceptance rate: 39.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:44 [loggers.py:257] Engine 000: Avg prompt throughput: 2759.3 tokens/s, Avg generation throughput: 2433.4 tokens/s, Running: 208 reqs, Waiting: 48 reqs, GPU KV cache usage: 99.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.20, Accepted throughput: 1324.20 tokens/s, Drafted throughput: 3296.86 tokens/s, Accepted: 13245 tokens, Drafted: 32976 tokens, Per-position acceptance rate: 0.632, 0.368, 0.205, Avg Draft acceptance rate: 40.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1630.6 tokens/s, Avg generation throughput: 2567.2 tokens/s, Running: 194 reqs, Waiting: 46 reqs, GPU KV cache usage: 92.8%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:36:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.09, Accepted throughput: 1333.56 tokens/s, Drafted throughput: 3685.40 tokens/s, Accepted: 13337 tokens, Drafted: 36858 tokens, Per-position acceptance rate: 0.595, 0.325, 0.166, Avg Draft acceptance rate: 36.2%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:04 [loggers.py:257] Engine 000: Avg prompt throughput: 1136.1 tokens/s, Avg generation throughput: 3118.7 tokens/s, Running: 157 reqs, Waiting: 87 reqs, GPU KV cache usage: 94.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.15, Accepted throughput: 1665.16 tokens/s, Drafted throughput: 4348.21 tokens/s, Accepted: 16655 tokens, Drafted: 43491 tokens, Per-position acceptance rate: 0.621, 0.349, 0.179, Avg Draft acceptance rate: 38.3%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:14 [loggers.py:257] Engine 000: Avg prompt throughput: 2497.5 tokens/s, Avg generation throughput: 2888.7 tokens/s, Running: 145 reqs, Waiting: 108 reqs, GPU KV cache usage: 98.5%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.20, Accepted throughput: 1569.23 tokens/s, Drafted throughput: 3932.87 tokens/s, Accepted: 15694 tokens, Drafted: 39333 tokens, Per-position acceptance rate: 0.629, 0.369, 0.199, Avg Draft acceptance rate: 39.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:24 [loggers.py:257] Engine 000: Avg prompt throughput: 2434.1 tokens/s, Avg generation throughput: 2483.9 tokens/s, Running: 179 reqs, Waiting: 76 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.22, Accepted throughput: 1358.39 tokens/s, Drafted throughput: 3351.78 tokens/s, Accepted: 13588 tokens, Drafted: 33528 tokens, Per-position acceptance rate: 0.638, 0.372, 0.206, Avg Draft acceptance rate: 40.5%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:34 [loggers.py:257] Engine 000: Avg prompt throughput: 2466.2 tokens/s, Avg generation throughput: 2369.9 tokens/s, Running: 213 reqs, Waiting: 37 reqs, GPU KV cache usage: 95.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.16, Accepted throughput: 1268.23 tokens/s, Drafted throughput: 3276.77 tokens/s, Accepted: 12684 tokens, Drafted: 32772 tokens, Per-position acceptance rate: 0.622, 0.352, 0.188, Avg Draft acceptance rate: 38.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:44 [loggers.py:257] Engine 000: Avg prompt throughput: 1194.1 tokens/s, Avg generation throughput: 2851.0 tokens/s, Running: 186 reqs, Waiting: 58 reqs, GPU KV cache usage: 95.3%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.14, Accepted throughput: 1514.94 tokens/s, Drafted throughput: 4000.08 tokens/s, Accepted: 15151 tokens, Drafted: 40005 tokens, Per-position acceptance rate: 0.614, 0.345, 0.177, Avg Draft acceptance rate: 37.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:54 [loggers.py:257] Engine 000: Avg prompt throughput: 1584.0 tokens/s, Avg generation throughput: 3188.9 tokens/s, Running: 140 reqs, Waiting: 111 reqs, GPU KV cache usage: 98.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:37:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1716.01 tokens/s, Drafted throughput: 4403.72 tokens/s, Accepted: 17160 tokens, Drafted: 44037 tokens, Per-position acceptance rate: 0.621, 0.355, 0.193, Avg Draft acceptance rate: 39.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:04 [loggers.py:257] Engine 000: Avg prompt throughput: 2443.6 tokens/s, Avg generation throughput: 2645.9 tokens/s, Running: 162 reqs, Waiting: 94 reqs, GPU KV cache usage: 99.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:04 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.18, Accepted throughput: 1427.68 tokens/s, Drafted throughput: 3622.03 tokens/s, Accepted: 14281 tokens, Drafted: 36231 tokens, Per-position acceptance rate: 0.626, 0.362, 0.195, Avg Draft acceptance rate: 39.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:14 [loggers.py:257] Engine 000: Avg prompt throughput: 2659.3 tokens/s, Avg generation throughput: 2364.0 tokens/s, Running: 210 reqs, Waiting: 46 reqs, GPU KV cache usage: 99.4%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:14 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.20, Accepted throughput: 1281.84 tokens/s, Drafted throughput: 3211.63 tokens/s, Accepted: 12825 tokens, Drafted: 32133 tokens, Per-position acceptance rate: 0.633, 0.365, 0.199, Avg Draft acceptance rate: 39.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:24 [loggers.py:257] Engine 000: Avg prompt throughput: 1745.6 tokens/s, Avg generation throughput: 2566.9 tokens/s, Running: 222 reqs, Waiting: 23 reqs, GPU KV cache usage: 97.9%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:24 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.12, Accepted throughput: 1352.70 tokens/s, Drafted throughput: 3620.43 tokens/s, Accepted: 13528 tokens, Drafted: 36207 tokens, Per-position acceptance rate: 0.610, 0.338, 0.174, Avg Draft acceptance rate: 37.4%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:34 [loggers.py:257] Engine 000: Avg prompt throughput: 745.5 tokens/s, Avg generation throughput: 3209.7 tokens/s, Running: 155 reqs, Waiting: 89 reqs, GPU KV cache usage: 95.6%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:34 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.17, Accepted throughput: 1727.42 tokens/s, Drafted throughput: 4441.95 tokens/s, Accepted: 17276 tokens, Drafted: 44424 tokens, Per-position acceptance rate: 0.627, 0.351, 0.189, Avg Draft acceptance rate: 38.9%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:44 [loggers.py:257] Engine 000: Avg prompt throughput: 2512.7 tokens/s, Avg generation throughput: 2904.8 tokens/s, Running: 154 reqs, Waiting: 100 reqs, GPU KV cache usage: 99.2%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:44 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.19, Accepted throughput: 1574.25 tokens/s, Drafted throughput: 3962.33 tokens/s, Accepted: 15744 tokens, Drafted: 39627 tokens, Per-position acceptance rate: 0.636, 0.361, 0.195, Avg Draft acceptance rate: 39.7%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:54 [loggers.py:257] Engine 000: Avg prompt throughput: 819.1 tokens/s, Avg generation throughput: 2756.5 tokens/s, Running: 4 reqs, Waiting: 0 reqs, GPU KV cache usage: 3.1%, Prefix cache hit rate: 0.0%
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:54 [metrics.py:100] SpecDecoding metrics: Mean acceptance length: 2.13, Accepted throughput: 1466.39 tokens/s, Drafted throughput: 3896.98 tokens/s, Accepted: 14664 tokens, Drafted: 38970 tokens, Per-position acceptance rate: 0.617, 0.338, 0.174, Avg Draft acceptance rate: 37.6%
tip: install termplotlib and gnuplot to plot the metrics
============ Serving Benchmark Result ============
Successful requests:                     2560      
Failed requests:                         0         
Maximum request concurrency:             256       
Request rate configured (RPS):           256.00    
Benchmark duration (s):                  188.45    
Total input tokens:                      373233    
Total generated tokens:                  511873    
Request throughput (req/s):              13.58     
Output token throughput (tok/s):         2716.23   
Peak output token throughput (tok/s):    2063.00   
Peak concurrent requests:                293.00    
Total token throughput (tok/s):          4696.78   
---------------Time to First Token----------------
Mean TTFT (ms):                          4366.67   
Median TTFT (ms):                        3253.59   
P99 TTFT (ms):                           10288.58  
-----Time per Output Token (excl. 1st token)------
Mean TPOT (ms):                          70.30     
Median TPOT (ms):                        67.02     
P99 TPOT (ms):                           111.47    
---------------Inter-token Latency----------------
Mean ITL (ms):                           151.52    
Median ITL (ms):                         107.23    
P99 ITL (ms):                            426.06    
---------------Speculative Decoding---------------
Acceptance rate (%):                     38.96     
Acceptance length:                       2.17      
Drafts:                                  235389    
Draft tokens:                            706167    
Accepted tokens:                         275134    
Per-position acceptance (%):
  Position 0:                            62.42     
  Position 1:                            35.53     
  Position 2:                            18.94     
==================================================
Benchmark completed, stopping server...
Cleaning up: removing container vllm-throughput-InstructCoder-sd-eagle3-Qwen3-32B-speculator.eagle3-k3-t0.0-tp1...
[0;36m(APIServer pid=3300916)[0;0m INFO 01-23 00:38:55 [launcher.py:110] Shutting down FastAPI HTTP server.
