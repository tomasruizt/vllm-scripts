{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1eee38",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_context(\"talk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d15542c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "\n",
        "analysis = \"qwen\"\n",
        "analysis = \"llama70b\"\n",
        "\n",
        "# Params for Qwen analysis\n",
        "folder = \"./logs-2026-01-23/\"\n",
        "dataset = \"mt-bench\"\n",
        "dataset = \"InstructCoder\"\n",
        "\n",
        "\n",
        "def load_qwen_results():\n",
        "    dirs = os.listdir(folder)\n",
        "    dirs = [Path(folder) / d for d in dirs]\n",
        "    throughput_dirs = [d for d in dirs if \"throughput\" in str(d)]\n",
        "    texts = ((d / \"0_out.logs\").read_text() for d in throughput_dirs)\n",
        "    all_rows = [find_params(t) for t in texts]\n",
        "    rows = [row for sublist in all_rows for row in sublist]\n",
        "    wide = pd.DataFrame(rows)\n",
        "    wide = shorten_dataset(wide)\n",
        "    wide = wide.query(\"dataset == @dataset\")\n",
        "    # Save full dataset\n",
        "    # wide.to_parquet(\"data-2026-01-23.parquet\")\n",
        "    return wide\n",
        "\n",
        "\n",
        "def load_llama70b_results():\n",
        "    ks = [3, 4, 5, 6, 7, 8]\n",
        "\n",
        "    directories = [\"../online-throughput/tp-results-nosd/\"]\n",
        "    for k in ks:\n",
        "        directories.append(f\"../online-throughput/k{k}/tp-results-draft-model/\")\n",
        "        directories.append(f\"../online-throughput/k{k}/tp-results-eagle3/\")\n",
        "    server_logfiles = [\"../online-throughput/tp-results-nosd/nosd-serve.log\"]\n",
        "    for k in ks:\n",
        "        server_logfiles.append(\n",
        "            f\"../online-throughput/k{k}/tp-results-draft-model/draft-model-serve.log\"\n",
        "        )\n",
        "        server_logfiles.append(\n",
        "            f\"../online-throughput/k{k}/tp-results-eagle3/eagle3-serve.log\"\n",
        "        )\n",
        "    rows = []\n",
        "    for dir, server_logfile in zip(directories, server_logfiles):\n",
        "        static_data = extract_server_params(Path(server_logfile).read_text())\n",
        "        for file in os.listdir(dir):\n",
        "            if \"bench\" in file:\n",
        "                client_logfile = Path(dir) / file\n",
        "                client_text = client_logfile.read_text()\n",
        "                row = extract_bench_metrics(client_text) | static_data\n",
        "                rows.append(row)\n",
        "\n",
        "    wide = pd.DataFrame(rows)\n",
        "    wide = shorten_dataset(wide)\n",
        "    return wide\n",
        "\n",
        "\n",
        "def extract_bench_metrics(client_logs: str) -> dict:\n",
        "    section = client_logs\n",
        "    results = {}\n",
        "\n",
        "    # match dataset_path='likaixin/InstructCoder'\n",
        "    dataset_match = re.search(r\"dataset_path='(.*?)'\", section)\n",
        "    results[\"dataset\"] = dataset_match.group(1)\n",
        "\n",
        "    temp_match = re.search(r\"temperature=([^,]+),\", section)\n",
        "    if temp_match:\n",
        "        results[\"temp\"] = float(temp_match.group(1))\n",
        "\n",
        "    # Parse benchmark duration\n",
        "    concurrency_match = re.search(r\"Maximum request concurrency:\\s+(\\d+)\", section)\n",
        "    if concurrency_match:\n",
        "        results[\"concurrency\"] = int(concurrency_match.group(1))\n",
        "\n",
        "    duration_match = re.search(r\"Benchmark duration \\(s\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    if duration_match:\n",
        "        results[\"benchmark_duration_s\"] = float(duration_match.group(1))\n",
        "\n",
        "    n_reqs = re.search(r\"Successful requests:\\s+(\\d+)\", section)\n",
        "    if n_reqs:\n",
        "        results[\"n_reqs\"] = int(n_reqs.group(1))\n",
        "\n",
        "    req_throughput = re.search(r\"Request throughput \\(req/s\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    if req_throughput:\n",
        "        results[\"req_throughput\"] = float(req_throughput.group(1))\n",
        "\n",
        "    acceptance_rate = re.search(r\"Acceptance rate \\(%\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    if acceptance_rate:\n",
        "        results[\"acceptance_rate\"] = float(acceptance_rate.group(1))\n",
        "\n",
        "    acceptance_length = re.search(r\"Acceptance length:\\s+(\\d+\\.\\d+)\", section)\n",
        "    if acceptance_length:\n",
        "        results[\"acceptance_length\"] = float(acceptance_length.group(1))\n",
        "\n",
        "    # Parse TTFT (Time to First Token)\n",
        "    ttft_mean = re.search(r\"Mean TTFT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    ttft_median = re.search(r\"Median TTFT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    ttft_p99 = re.search(r\"P99 TTFT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "\n",
        "    results[\"mean_ttft\"] = float(ttft_mean.group(1)) if ttft_mean else None\n",
        "    results[\"median_ttft\"] = float(ttft_median.group(1)) if ttft_median else None\n",
        "    results[\"p99_ttft\"] = float(ttft_p99.group(1)) if ttft_p99 else None\n",
        "\n",
        "    # Parse TPOT (Time per Output Token)\n",
        "    tpot_mean = re.search(r\"Mean TPOT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    tpot_median = re.search(r\"Median TPOT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    tpot_p99 = re.search(r\"P99 TPOT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "\n",
        "    results[\"mean_tpot\"] = float(tpot_mean.group(1)) if tpot_mean else None\n",
        "    results[\"median_tpot\"] = float(tpot_median.group(1)) if tpot_median else None\n",
        "    results[\"p99_tpot\"] = float(tpot_p99.group(1)) if tpot_p99 else None\n",
        "\n",
        "    # Parse ITL (Inter-token Latency)\n",
        "    itl_mean = re.search(r\"Mean ITL \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    itl_median = re.search(r\"Median ITL \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "    itl_p99 = re.search(r\"P99 ITL \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "\n",
        "    results[\"mean_itl\"] = float(itl_mean.group(1)) if itl_mean else None\n",
        "    results[\"median_itl\"] = float(itl_median.group(1)) if itl_median else None\n",
        "    results[\"p99_itl\"] = float(itl_p99.group(1)) if itl_p99 else None\n",
        "\n",
        "    # Parse total token throughput\n",
        "    throughput_match = re.search(\n",
        "        r\"Total token throughput \\(tok/s\\):\\s+(\\d+\\.\\d+)\", section\n",
        "    )\n",
        "    results[\"total_token_throughput\"] = (\n",
        "        float(throughput_match.group(1)) if throughput_match else None\n",
        "    )\n",
        "    return results\n",
        "\n",
        "\n",
        "def shorten_dataset(df):\n",
        "    df[\"dataset\"] = df[\"dataset\"].str.split(\"/\").str[1]\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_server_params(server_logs: str) -> dict:\n",
        "    text = server_logs\n",
        "    # Parse sd method from the full text (appears in header, not in benchmark sections)\n",
        "    # e.g. 'speculative_config': {'method': 'draft_model', ...\n",
        "    method_match = re.search(r\"'speculative_config': (\\{.*?\\})\", text, re.DOTALL)\n",
        "    static_data = {\"sd_method\": \"None\", \"num_spec_toks\": 0, \"draft_model\": \"None\"}\n",
        "    if method_match:\n",
        "        sd_data = ast.literal_eval(method_match.group(1))\n",
        "        static_data[\"sd_method\"] = sd_data[\"method\"]\n",
        "        static_data[\"num_spec_toks\"] = sd_data[\"num_speculative_tokens\"]\n",
        "        static_data[\"draft_model\"] = sd_data[\"model\"]\n",
        "\n",
        "    # match tensor_parallel_size=1\n",
        "    tp_match = re.search(r\"tensor_parallel_size=(\\d+)\", text)\n",
        "    if tp_match:\n",
        "        static_data[\"tp\"] = int(tp_match.group(1))\n",
        "    return static_data\n",
        "\n",
        "\n",
        "def find_params(text: str):\n",
        "    \"\"\"\n",
        "    Parse benchmark results from vLLM serving benchmark output.\n",
        "    Handles multiple benchmark result sections in the same log file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries, each containing parsed metrics for one benchmark run\n",
        "    \"\"\"\n",
        "    static_data = extract_server_params(text)\n",
        "\n",
        "    # Split text by benchmark result sections\n",
        "    delimiter = \"Namespace\"\n",
        "    sections = text.split(delimiter)\n",
        "    sections = sections[:1] + [delimiter + s for s in sections[1:]]\n",
        "\n",
        "    all_results = []\n",
        "    for section in sections[1:]:  # Skip the first split (content before first section)\n",
        "        # Use the sd_method found in the header for all benchmark results\n",
        "        results = extract_bench_metrics(client_logs=section)\n",
        "        results = results | static_data\n",
        "        all_results.append(results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "if analysis == \"qwen\":\n",
        "    tp_wide_allk = load_qwen_results()\n",
        "elif analysis == \"llama70b\":\n",
        "    tp_wide_allk = load_llama70b_results()\n",
        "else:\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e24067ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "tp_wide_allk.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af6a002",
      "metadata": {},
      "outputs": [],
      "source": [
        "folder = f\"imgs/{analysis}/{dataset}\"\n",
        "os.makedirs(folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992ca8c2",
      "metadata": {},
      "source": [
        "# Analysis of Best Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe88728",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mk_ratios_long(wide):\n",
        "    keys = [\"concurrency\"]\n",
        "    baseline = wide.query(\"sd_method == 'None'\")[[*keys, \"total_token_throughput\"]]\n",
        "    non_baseline = wide.query(\"sd_method != 'None'\")[\n",
        "        [\"sd_method\", \"draft_model\", \"num_spec_toks\", *keys, \"total_token_throughput\"]\n",
        "    ]\n",
        "    assert not non_baseline.drop(columns=[\"total_token_throughput\"]).duplicated().any()\n",
        "    ratios = baseline.merge(non_baseline, on=keys, suffixes=[\"_baseline\", \"\"])\n",
        "    ratios[\"ratio\"] = (\n",
        "        ratios[\"total_token_throughput\"] / ratios[\"total_token_throughput_baseline\"]\n",
        "    )\n",
        "    return ratios\n",
        "\n",
        "\n",
        "def rename_sd_method(df):\n",
        "    map = {\n",
        "        \"draft_model\": \"Draft Model\",\n",
        "        \"eagle3\": \"Eagle3\",\n",
        "        \"None\": \"None\",\n",
        "    }\n",
        "    return df.assign(**{\"sd_method\": df[\"sd_method\"].map(map)})\n",
        "\n",
        "\n",
        "ratios = mk_ratios_long(tp_wide_allk)\n",
        "ratios.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d993241a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# concurrency_ticks = tp_wide_allk[\"concurrency\"].unique()\n",
        "if dataset == \"InstructCoder\":\n",
        "    concurrency_ticks = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
        "else:\n",
        "    concurrency_ticks = [1, 2, 4, 8, 16, 32, 64, 80]\n",
        "\n",
        "palette = \"viridis\"\n",
        "\n",
        "axs = sns.relplot(\n",
        "    ratios.query(\"sd_method == 'draft_model'\"),\n",
        "    x=\"concurrency\",\n",
        "    y=\"ratio\",\n",
        "    col=\"draft_model\",\n",
        "    hue=\"num_spec_toks\",\n",
        "    palette=palette,\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        ")\n",
        "axs.set_titles(\"Draft Model: {col_name}\")\n",
        "for ax in axs.axes.flat:\n",
        "    ax.grid(True, alpha=0.5, axis=\"y\")\n",
        "    if analysis == \"qwen\":\n",
        "        ymax = 2.5\n",
        "    elif analysis == \"llama70b\":\n",
        "        ymax = 4\n",
        "    ax.set_ylim(0, ymax)\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "    ax.minorticks_off()\n",
        "    ax.set_ylabel(\"Speedup Ratio\")\n",
        "    ax.set_xlabel(\"Batch Size\")\n",
        "    ax.axhline(1, color=\"k\", linestyle=\"--\")\n",
        "\n",
        "sns.move_legend(\n",
        "    axs,\n",
        "    \"upper center\",\n",
        "    ncol=3,\n",
        "    bbox_to_anchor=(0.5, 1.2),\n",
        "    title=\"Number of Speculative Tokens\",\n",
        ")\n",
        "axs.figure.tight_layout()\n",
        "axs.figure.savefig(folder + \"/draft_model_ratios.png\", dpi=300, bbox_inches=\"tight\")\n",
        "# best config in low concurrency is num_spec_toks=4, draft_model=Qwen3-1.7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e88b65",
      "metadata": {},
      "outputs": [],
      "source": [
        "if analysis == \"qwen\":\n",
        "    draft_model = \"Qwen/Qwen3-1.7B\"\n",
        "elif analysis == \"llama70b\":\n",
        "    draft_model = \"meta-llama/Llama-3.2-1B\"\n",
        "\n",
        "if analysis == \"qwen\":\n",
        "    best_k = 4\n",
        "elif analysis == \"llama70b\":\n",
        "    best_k = 7\n",
        "\n",
        "best_draft_model = tp_wide_allk.query(\n",
        "    \"sd_method == 'draft_model' and num_spec_toks == @best_k and draft_model == @draft_model\"\n",
        ")\n",
        "assert len(best_draft_model) != 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada8fa2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = sns.relplot(\n",
        "    ratios.query(\"sd_method == 'eagle3'\"),\n",
        "    x=\"concurrency\",\n",
        "    y=\"ratio\",\n",
        "    hue=\"num_spec_toks\",\n",
        "    palette=palette,\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        "    aspect=1.3,  # make figure wider\n",
        ")\n",
        "for ax in axs.axes.flat:\n",
        "    ax.grid(True, alpha=0.5, axis=\"y\")\n",
        "    ax.set_ylim(0, ymax)\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "    ax.minorticks_off()\n",
        "    ax.set_ylabel(\"Speedup Ratio\")\n",
        "    ax.set_xlabel(\"Batch Size\")\n",
        "    ax.axhline(1, color=\"k\", linestyle=\"--\")\n",
        "\n",
        "sns.move_legend(\n",
        "    axs,\n",
        "    \"upper center\",\n",
        "    ncol=3,\n",
        "    bbox_to_anchor=(0.45, 1.2),\n",
        "    title=\"Number of Speculative Tokens\",\n",
        ")\n",
        "axs.figure.tight_layout()\n",
        "axs.figure.savefig(folder + \"/eagle3_ratios.png\", dpi=300, bbox_inches=\"tight\")\n",
        "# best config in low concurrency is num_spec_toks=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10dec7f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_eagle3 = tp_wide_allk.query(\"sd_method == 'eagle3' and num_spec_toks == @best_k\")\n",
        "assert len(best_eagle3) != 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f19b739",
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline = tp_wide_allk.query(\"sd_method == 'None'\")\n",
        "tp_wide = pd.concat([best_draft_model, best_eagle3, baseline])\n",
        "tp_wide.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d824842d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mk_long(wide):\n",
        "    long = wide.melt(\n",
        "        id_vars=[\n",
        "            # \"directory\",\n",
        "            \"sd_method\",\n",
        "            \"draft_model\",\n",
        "            \"num_spec_toks\",\n",
        "            \"concurrency\",\n",
        "            \"temp\",\n",
        "        ],\n",
        "        # value_vars=[\"mean_ttft\", \"mean_tpot\", \"mean_itl\"],\n",
        "        # value_vars=[\"median_ttft\", \"median_tpot\", \"median_itl\"],\n",
        "        value_vars=[\"p99_ttft\", \"p99_tpot\", \"p99_itl\"],\n",
        "    )\n",
        "    return long\n",
        "\n",
        "\n",
        "tp_long = mk_long(tp_wide)\n",
        "tp_long.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad57b2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.ticker as mticker\n",
        "\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "# Format yticks as 1000 rather than 10^3\n",
        "fmt = mticker.FuncFormatter(lambda x, _: \"{:g}\".format(x))\n",
        "\n",
        "fg = sns.relplot(\n",
        "    rename_sd_method(tp_long.query(\"temp == 0.0\")),\n",
        "    x=\"concurrency\",\n",
        "    y=\"value\",\n",
        "    hue=\"sd_method\",\n",
        "    style=\"sd_method\",\n",
        "    col=\"variable\",\n",
        "    col_wrap=3,\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        "    facet_kws={\"sharey\": False},\n",
        ")\n",
        "\n",
        "for i, ax in enumerate(fg.axes.flat):\n",
        "    ax.grid(True, alpha=0.5)\n",
        "    ax.set_xscale(\"log\")\n",
        "    if i in [0, 1, 2]:  # 1st and 3rd diagram\n",
        "        ax.set_yscale(\"log\")\n",
        "        ax.yaxis.set_major_formatter(fmt)\n",
        "        # ax.yaxis.set_minor_formatter(fmt)\n",
        "    else:\n",
        "        ax.set_ylim(0, None)\n",
        "    ax.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "    ax.xaxis.minorticks_off()  # Hide minor ticks\n",
        "\n",
        "fg.set_ylabels(\"Time (ms)\")\n",
        "fg.set_xlabels(\"Batch Size\")\n",
        "fg.set_titles(\"Metric: {col_name}\")\n",
        "\n",
        "# Set legend location above the plots and make it horizontal\n",
        "fg.legend.set_title(\"Speculative Decoding\")\n",
        "sns.move_legend(fg, \"upper center\", ncol=3, bbox_to_anchor=(0.45, 1.2))\n",
        "fg.figure.tight_layout()\n",
        "fg.figure.savefig(folder + \"/ttft_itl_tpot.png\", dpi=300, bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2c70b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = sns.lineplot(\n",
        "    rename_sd_method(tp_wide.query(\"temp == 0.0\")),\n",
        "    x=\"concurrency\",\n",
        "    y=\"req_throughput\",\n",
        "    hue=\"sd_method\",\n",
        "    style=\"sd_method\",\n",
        "    marker=\"o\",\n",
        ")\n",
        "fig.grid(True, alpha=0.5)\n",
        "fig.set_xscale(\"log\")\n",
        "fig.set_yscale(\"log\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "yticks = [0.1, 0.5, 1, 2, 4, 8, 16]\n",
        "fig.set_yticks(yticks, labels=yticks)\n",
        "fig.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "fig.minorticks_off()  # Hide minor ticks\n",
        "fig.set_title(\"Request Throughput (req/s)\")\n",
        "fig.set_ylabel(\"\")\n",
        "fig.legend(title=\"Speculative Decoding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ecb396",
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHORT COMPARISON\n",
        "fig = sns.barplot(\n",
        "    rename_sd_method(\n",
        "        tp_wide.query(\"temp == 0.0 and sd_method != 'eagle3' and concurrency <= 80\")\n",
        "    ),\n",
        "    x=\"concurrency\",\n",
        "    y=\"total_token_throughput\",\n",
        "    hue=\"sd_method\",\n",
        ")\n",
        "fig.set_title(\"Token Throughput (tok/s)\")\n",
        "fig.set_ylabel(\"\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "fig.legend(title=\"Speculative Decoding\")\n",
        "fig.grid(True, alpha=0.5, axis=\"y\")\n",
        "fig.figure.tight_layout()\n",
        "fig.figure.savefig(\n",
        "    folder + \"/total_token_throughput_short.png\", dpi=300, bbox_inches=\"tight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52020ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# FULL COMPARISON\n",
        "fig = sns.barplot(\n",
        "    rename_sd_method(tp_wide.query(\"temp == 0.0\")),\n",
        "    x=\"concurrency\",\n",
        "    y=\"total_token_throughput\",\n",
        "    hue=\"sd_method\",\n",
        ")\n",
        "fig.set_title(\"Total Token Throughput (tok/s)\")\n",
        "fig.set_ylabel(\"\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "fig.legend(title=\"Speculative Decoding\")\n",
        "fig.grid(True, alpha=0.5, axis=\"y\")\n",
        "fig.figure.tight_layout()\n",
        "fig.figure.savefig(\n",
        "    folder + \"/total_token_throughput_full.png\", dpi=300, bbox_inches=\"tight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa782d93",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = sns.barplot(\n",
        "    rename_sd_method(mk_ratios_long(tp_wide)),\n",
        "    x=\"concurrency\",\n",
        "    y=\"ratio\",\n",
        "    hue=\"sd_method\",\n",
        ")\n",
        "fig.set_ylim(0, ymax)\n",
        "fig.axhline(1, color=\"k\", linestyle=\"--\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "fig.set_ylabel(\"Speedup Ratio\")\n",
        "fig.grid(True, alpha=0.5, axis=\"y\")\n",
        "\n",
        "sns.move_legend(fig, \"lower center\", ncol=2, bbox_to_anchor=(0.5, 1), title=\"Method\")\n",
        "fig.figure.tight_layout()\n",
        "fig.figure.savefig(\n",
        "    folder + \"/draft_model_vs_eagle3_ratios.png\", dpi=300, bbox_inches=\"tight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1128ec47",
      "metadata": {},
      "source": [
        "# AL and AR Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d006917a",
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = sns.relplot(\n",
        "    rename_sd_method(tp_wide_allk.query(\"sd_method != 'None'\")),\n",
        "    x=\"num_spec_toks\",\n",
        "    y=\"acceptance_length\",\n",
        "    style=\"sd_method\",\n",
        "    hue=\"draft_model\",\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        "    aspect=1.3,\n",
        ")\n",
        "axs.set_titles(\"#SpecTokens = {col_name}\")\n",
        "\n",
        "for ax in axs.axes.flat:\n",
        "    ax.grid(True, alpha=0.5, axis=\"y\")\n",
        "    ax.set_ylim(0, 6)\n",
        "    ax.set_ylabel(\"Acceptance Length\")\n",
        "    ax.set_xlabel(\"Number of Speculative Tokens\")\n",
        "sns.move_legend(\n",
        "    axs,\n",
        "    \"right\",\n",
        "    ncol=1,\n",
        "    bbox_to_anchor=(1.02, 0.5),\n",
        "    title=\"Method\",\n",
        ")\n",
        "axs.figure.savefig(\n",
        "    folder + \"/acceptance_length_vs_num_spec_toks.png\", dpi=300, bbox_inches=\"tight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da601083",
      "metadata": {},
      "outputs": [],
      "source": [
        "ratios.query(\n",
        "    \"sd_method == 'draft_model' and num_spec_toks == 4 and draft_model == '@draft_model' and concurrency <= 64\"\n",
        ").round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a539129",
      "metadata": {},
      "outputs": [],
      "source": [
        "ratios.iloc[ratios[\"ratio\"].argmax()]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
