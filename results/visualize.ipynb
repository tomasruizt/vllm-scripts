{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bc90d2fa",
      "metadata": {},
      "source": [
        "Command:\n",
        "```shell\n",
        "lrzcpy /dss/dssfs02/lwp-dss-0001/pn76je/pn76je-dss-0000/vllm/logs-2026-01-20\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1eee38",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_context(\"talk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d15542c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import ast\n",
        "\n",
        "folder = \"/home/tomasruiz/code/vllm-scripts/slurm/results/logs-2026-01-21/\"\n",
        "\n",
        "\n",
        "def find_params(dirname: str) -> list:\n",
        "    \"\"\"\n",
        "    directory name has the format:\n",
        "        \"<somename>-(sd|nosd)-t(<temp>)-tp(<tensor-parallel-size>)\"\n",
        "    e.g.\n",
        "        \"vllm-throughput-nosd-t0.0-tp4\"\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries, one per benchmark result\n",
        "    \"\"\"\n",
        "    if \"tp\" in dirname:\n",
        "        *_, temp, tp = dirname.split(\"-\")\n",
        "    else:\n",
        "        *_, temp, tp = dirname.split(\"-\")\n",
        "        tp = None\n",
        "    with open(os.path.join(folder, dirname, \"0_out.logs\"), \"r\") as f:\n",
        "        text = f.read()\n",
        "    parsed_results = parse_benchmark_results(text)\n",
        "\n",
        "    # Create one row per benchmark result\n",
        "    rows = []\n",
        "    for parsed in parsed_results:\n",
        "        rows.append(\n",
        "            {\n",
        "                \"directory\": dirname,\n",
        "                # \"sd\": sd == \"sd\", <<< We read SD method now from the vLLM arguments\n",
        "                \"temp\": float(temp.replace(\"t\", \"\")),\n",
        "                \"tp\": int(tp.replace(\"tp\", \"\")) if tp else None,\n",
        "                **parsed,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return rows\n",
        "\n",
        "\n",
        "def parse_benchmark_results(text: str):\n",
        "    \"\"\"\n",
        "    Parse benchmark results from vLLM serving benchmark output.\n",
        "    Handles multiple benchmark result sections in the same log file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of dictionaries, each containing parsed metrics for one benchmark run\n",
        "    \"\"\"\n",
        "    # Parse sd method from the full text (appears in header, not in benchmark sections)\n",
        "    # e.g. 'speculative_config': {'method': 'draft_model', ...\n",
        "    method_match = re.search(r\"'speculative_config': (\\{.*?\\})\", text, re.DOTALL)\n",
        "    sd_results = {\"sd_method\": \"None\", \"num_spec_toks\": 0, \"draft_model\": \"None\"}\n",
        "    if method_match:\n",
        "        sd_data = ast.literal_eval(method_match.group(1))\n",
        "        sd_results[\"sd_method\"] = sd_data[\"method\"]\n",
        "        sd_results[\"num_spec_toks\"] = sd_data[\"num_speculative_tokens\"]\n",
        "        sd_results[\"draft_model\"] = sd_data[\"model\"]\n",
        "\n",
        "    # match dataset_path='likaixin/InstructCoder'\n",
        "    dataset_match = re.search(r\"dataset_path='(.*?)'\", text)\n",
        "    if dataset_match:\n",
        "        sd_results[\"dataset\"] = dataset_match.group(1)\n",
        "\n",
        "    # Split text by benchmark result sections\n",
        "    sections = re.split(r\"============ Serving Benchmark Result ============\", text)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for section in sections[1:]:  # Skip the first split (content before first section)\n",
        "        # Use the sd_method found in the header for all benchmark results\n",
        "        results = {**sd_results}\n",
        "\n",
        "        # Parse benchmark duration\n",
        "        concurrency_match = re.search(r\"Maximum request concurrency:\\s+(\\d+)\", section)\n",
        "        if concurrency_match:\n",
        "            results[\"concurrency\"] = int(concurrency_match.group(1))\n",
        "\n",
        "        duration_match = re.search(r\"Benchmark duration \\(s\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        if duration_match:\n",
        "            results[\"benchmark_duration_s\"] = float(duration_match.group(1))\n",
        "\n",
        "        n_reqs = re.search(r\"Successful requests:\\s+(\\d+)\", section)\n",
        "        if n_reqs:\n",
        "            results[\"n_reqs\"] = int(n_reqs.group(1))\n",
        "\n",
        "        req_throughput = re.search(\n",
        "            r\"Request throughput \\(req/s\\):\\s+(\\d+\\.\\d+)\", section\n",
        "        )\n",
        "        if req_throughput:\n",
        "            results[\"req_throughput\"] = float(req_throughput.group(1))\n",
        "\n",
        "        acceptance_rate = re.search(r\"Acceptance rate \\(%\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        if acceptance_rate:\n",
        "            results[\"acceptance_rate\"] = float(acceptance_rate.group(1))\n",
        "\n",
        "        acceptance_length = re.search(r\"Acceptance length:\\s+(\\d+\\.\\d+)\", section)\n",
        "        if acceptance_length:\n",
        "            results[\"acceptance_length\"] = float(acceptance_length.group(1))\n",
        "\n",
        "        # Parse TTFT (Time to First Token)\n",
        "        ttft_mean = re.search(r\"Mean TTFT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        ttft_median = re.search(r\"Median TTFT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        ttft_p99 = re.search(r\"P99 TTFT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "\n",
        "        results[\"mean_ttft\"] = float(ttft_mean.group(1)) if ttft_mean else None\n",
        "        results[\"median_ttft\"] = float(ttft_median.group(1)) if ttft_median else None\n",
        "        results[\"p99_ttft\"] = float(ttft_p99.group(1)) if ttft_p99 else None\n",
        "\n",
        "        # Parse TPOT (Time per Output Token)\n",
        "        tpot_mean = re.search(r\"Mean TPOT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        tpot_median = re.search(r\"Median TPOT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        tpot_p99 = re.search(r\"P99 TPOT \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "\n",
        "        results[\"mean_tpot\"] = float(tpot_mean.group(1)) if tpot_mean else None\n",
        "        results[\"median_tpot\"] = float(tpot_median.group(1)) if tpot_median else None\n",
        "        results[\"p99_tpot\"] = float(tpot_p99.group(1)) if tpot_p99 else None\n",
        "\n",
        "        # Parse ITL (Inter-token Latency)\n",
        "        itl_mean = re.search(r\"Mean ITL \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        itl_median = re.search(r\"Median ITL \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "        itl_p99 = re.search(r\"P99 ITL \\(ms\\):\\s+(\\d+\\.\\d+)\", section)\n",
        "\n",
        "        results[\"mean_itl\"] = float(itl_mean.group(1)) if itl_mean else None\n",
        "        results[\"median_itl\"] = float(itl_median.group(1)) if itl_median else None\n",
        "        results[\"p99_itl\"] = float(itl_p99.group(1)) if itl_p99 else None\n",
        "\n",
        "        # Parse total token throughput\n",
        "        throughput_match = re.search(\n",
        "            r\"Total token throughput \\(tok/s\\):\\s+(\\d+\\.\\d+)\", section\n",
        "        )\n",
        "        results[\"total_token_throughput\"] = (\n",
        "            float(throughput_match.group(1)) if throughput_match else None\n",
        "        )\n",
        "\n",
        "        # Only add if we found at least some metrics\n",
        "        if results:\n",
        "            all_results.append(results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "dirs = os.listdir(folder)\n",
        "throughput_dirs = [d for d in dirs if \"throughput\" in d]\n",
        "all_rows = [find_params(d) for d in throughput_dirs]\n",
        "rows = [row for sublist in all_rows for row in sublist]\n",
        "tp_wide_allk = pd.DataFrame(rows)\n",
        "tp_wide_allk[\"dataset\"] = (\n",
        "    tp_wide_allk[\"dataset\"].str.split(\"/\").str[1]\n",
        ")  # shorten dataset\n",
        "# filter\n",
        "dataset = \"mt-bench\"\n",
        "dataset = \"InstructCoder\"\n",
        "tp_wide_allk = tp_wide_allk.query(\"tp == 1 and dataset == @dataset\")\n",
        "tp_wide_allk.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "992ca8c2",
      "metadata": {},
      "source": [
        "# Analysis of Best Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe88728",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mk_ratios_long(wide):\n",
        "    keys = [\"concurrency\"]\n",
        "    baseline = wide.query(\"sd_method == 'None'\")[[*keys, \"total_token_throughput\"]]\n",
        "    non_baseline = wide.query(\"sd_method != 'None'\")[\n",
        "        [\"sd_method\", \"draft_model\", \"num_spec_toks\", *keys, \"total_token_throughput\"]\n",
        "    ]\n",
        "    assert not non_baseline.drop(columns=[\"total_token_throughput\"]).duplicated().any()\n",
        "    ratios = baseline.merge(non_baseline, on=keys, suffixes=[\"_baseline\", \"\"])\n",
        "    ratios[\"ratio\"] = (\n",
        "        ratios[\"total_token_throughput\"] / ratios[\"total_token_throughput_baseline\"]\n",
        "    )\n",
        "    return ratios\n",
        "\n",
        "\n",
        "def rename_sd_method(df):\n",
        "    map = {\n",
        "        \"draft_model\": \"Draft Model\",\n",
        "        \"eagle3\": \"Eagle3\",\n",
        "        \"None\": \"None\",\n",
        "    }\n",
        "    return df.assign(**{\"sd_method\": df[\"sd_method\"].map(map)})\n",
        "\n",
        "\n",
        "ratios = mk_ratios_long(tp_wide_allk)\n",
        "ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74326136",
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d993241a",
      "metadata": {},
      "outputs": [],
      "source": [
        "concurrency_ticks = tp_wide_allk[\"concurrency\"].unique()\n",
        "\n",
        "axs = sns.relplot(\n",
        "    ratios.query(\"sd_method == 'draft_model'\"),\n",
        "    x=\"concurrency\",\n",
        "    y=\"ratio\",\n",
        "    col=\"draft_model\",\n",
        "    hue=\"num_spec_toks\",\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        ")\n",
        "axs.set_titles(\"Draft Model: {col_name}\")\n",
        "for ax in axs.axes.flat:\n",
        "    ax.grid(True, alpha=0.5, axis=\"y\")\n",
        "    ax.set_ylim(0, None)\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "    ax.minorticks_off()\n",
        "    ax.set_ylabel(\"Speedup Ratio\")\n",
        "    ax.set_xlabel(\"Batch Size\")\n",
        "    ax.axhline(1, color=\"k\", linestyle=\"--\")\n",
        "\n",
        "sns.move_legend(\n",
        "    axs,\n",
        "    \"upper center\",\n",
        "    ncol=3,\n",
        "    bbox_to_anchor=(0.5, 1.2),\n",
        "    title=\"Number of Speculative Tokens\",\n",
        ")\n",
        "axs.figure.tight_layout()\n",
        "axs.figure.savefig(\"imgs/draft_model_ratios.png\", dpi=300, bbox_inches=\"tight\")\n",
        "# best config in low concurrency is num_spec_toks=4, draft_model=Qwen3-1.7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e88b65",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_draft_model = tp_wide_allk.query(\n",
        "    \"sd_method == 'draft_model' and num_spec_toks == 4 and draft_model == 'Qwen/Qwen3-1.7B'\"\n",
        ")\n",
        "assert len(best_draft_model) != 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada8fa2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = sns.relplot(\n",
        "    ratios.query(\"sd_method == 'eagle3'\"),\n",
        "    x=\"concurrency\",\n",
        "    y=\"ratio\",\n",
        "    hue=\"num_spec_toks\",\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        "    aspect=1.3,  # make figure wider\n",
        ")\n",
        "for ax in axs.axes.flat:\n",
        "    ax.grid(True, alpha=0.5, axis=\"y\")\n",
        "    ax.set_ylim(0, None)\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "    ax.minorticks_off()\n",
        "    ax.set_ylabel(\"Speedup Ratio\")\n",
        "    ax.set_xlabel(\"Batch Size\")\n",
        "    ax.axhline(1, color=\"k\", linestyle=\"--\")\n",
        "\n",
        "sns.move_legend(\n",
        "    axs,\n",
        "    \"upper center\",\n",
        "    ncol=3,\n",
        "    bbox_to_anchor=(0.45, 1.2),\n",
        "    title=\"Number of Speculative Tokens\",\n",
        ")\n",
        "# best config in low concurrency is num_spec_toks=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10dec7f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "best_eagle3 = tp_wide_allk.query(\"sd_method == 'eagle3' and num_spec_toks == 4\")\n",
        "assert len(best_eagle3) != 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f19b739",
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline = tp_wide_allk.query(\"sd_method == 'None'\")\n",
        "tp_wide = pd.concat([best_draft_model, best_eagle3, baseline])\n",
        "tp_wide.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d824842d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mk_long(wide):\n",
        "    long = wide.melt(\n",
        "        id_vars=[\n",
        "            \"directory\",\n",
        "            \"sd_method\",\n",
        "            \"draft_model\",\n",
        "            \"num_spec_toks\",\n",
        "            \"concurrency\",\n",
        "            \"temp\",\n",
        "        ],\n",
        "        # value_vars=[\"mean_tpot\", \"mean_itl\", \"mean_ttft\"],\n",
        "        value_vars=[\"median_tpot\", \"median_itl\", \"median_ttft\"],\n",
        "        # value_vars=[\"p99_tpot\", \"p99_itl\", \"p99_ttft\"],\n",
        "    )\n",
        "    return long\n",
        "\n",
        "\n",
        "tp_long = mk_long(tp_wide)\n",
        "tp_long.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad57b2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "fg = sns.relplot(\n",
        "    rename_sd_method(tp_long.query(\"temp == 0.0\")),\n",
        "    x=\"concurrency\",\n",
        "    y=\"value\",\n",
        "    hue=\"sd_method\",\n",
        "    style=\"sd_method\",\n",
        "    col=\"variable\",\n",
        "    col_wrap=3,\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        "    facet_kws={\"sharey\": False},\n",
        ")\n",
        "\n",
        "for i, ax in enumerate(fg.axes.flat):\n",
        "    ax.grid(True, alpha=0.5)\n",
        "    ax.set_xscale(\"log\")\n",
        "    if i == 2:  # last diagram\n",
        "        ax.set_yscale(\"log\")\n",
        "    else:\n",
        "        ax.set_ylim(0, None)\n",
        "    ax.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "    ax.minorticks_off()  # Hide minor ticks\n",
        "\n",
        "\n",
        "fg.set_ylabels(\"Time (ms)\")\n",
        "fg.set_xlabels(\"Batch Size\")\n",
        "fg.set_titles(\"Metric: {col_name}\")\n",
        "\n",
        "# Set legend location above the plots and make it horizontal\n",
        "fg.legend.set_title(\"Speculative Decoding\")\n",
        "sns.move_legend(fg, \"upper center\", ncol=3, bbox_to_anchor=(0.45, 1.2))\n",
        "fg.figure.tight_layout()\n",
        "fg.figure.savefig(\"imgs/ttft_itl_tpot.png\", dpi=300, bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2c70b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = sns.lineplot(\n",
        "    tp_wide.query(\"temp == 0.0\"),\n",
        "    x=\"concurrency\",\n",
        "    y=\"req_throughput\",\n",
        "    hue=\"sd_method\",\n",
        "    style=\"sd_method\",\n",
        "    marker=\"o\",\n",
        ")\n",
        "fig.grid(True, alpha=0.5)\n",
        "fig.set_xscale(\"log\")\n",
        "fig.set_yscale(\"log\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "# yticks = [10, 20, 50, 100, 200, 500]\n",
        "# axs.set_yticks(yticks, labels=yticks)\n",
        "fig.set_xticks(concurrency_ticks, labels=concurrency_ticks)\n",
        "fig.minorticks_off()  # Hide minor ticks\n",
        "fig.set_ylabel(\"Request Throughput (req/s)\")\n",
        "fig.legend(title=\"Speculative Decoding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ecb396",
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHORT COMPARISON\n",
        "fig = sns.barplot(\n",
        "    rename_sd_method(\n",
        "        tp_wide.query(\"temp == 0.0 and sd_method != 'eagle3' and concurrency <= 64\")\n",
        "    ),\n",
        "    x=\"concurrency\",\n",
        "    y=\"total_token_throughput\",\n",
        "    hue=\"sd_method\",\n",
        ")\n",
        "fig.set_title(\"Token Throughput (tok/s)\")\n",
        "fig.set_ylabel(\"\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "fig.legend(title=\"Speculative Decoding\")\n",
        "fig.grid(True, alpha=0.5, axis=\"y\")\n",
        "fig.figure.tight_layout()\n",
        "fig.figure.savefig(\n",
        "    \"imgs/total_token_throughput_short.png\", dpi=300, bbox_inches=\"tight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52020ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# FULL COMPARISON\n",
        "fig = sns.barplot(\n",
        "    rename_sd_method(tp_wide.query(\"temp == 0.0\")),\n",
        "    x=\"concurrency\",\n",
        "    y=\"total_token_throughput\",\n",
        "    hue=\"sd_method\",\n",
        ")\n",
        "fig.set_title(\"Total Token Throughput (tok/s)\")\n",
        "fig.set_ylabel(\"\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "fig.legend(title=\"Speculative Decoding\")\n",
        "fig.grid(True, alpha=0.5, axis=\"y\")\n",
        "fig.figure.tight_layout()\n",
        "fig.figure.savefig(\"imgs/total_token_throughput_full.png\", dpi=300, bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa782d93",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = sns.barplot(\n",
        "    rename_sd_method(mk_ratios_long(tp_wide)),\n",
        "    x=\"concurrency\",\n",
        "    y=\"ratio\",\n",
        "    hue=\"sd_method\",\n",
        ")\n",
        "fig.set_ylim(0, None)\n",
        "fig.axhline(1, color=\"k\", linestyle=\"--\")\n",
        "fig.set_xlabel(\"Batch Size\")\n",
        "fig.set_ylabel(\"Speedup Ratio\")\n",
        "fig.grid(True, alpha=0.5, axis=\"y\")\n",
        "\n",
        "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.4), ncol=2, title=\"Method\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1128ec47",
      "metadata": {},
      "source": [
        "# AL and AR Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d006917a",
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = sns.relplot(\n",
        "    rename_sd_method(tp_wide_allk.query(\"sd_method != 'None'\")),\n",
        "    x=\"num_spec_toks\",\n",
        "    y=\"acceptance_length\",\n",
        "    style=\"sd_method\",\n",
        "    hue=\"draft_model\",\n",
        "    kind=\"line\",\n",
        "    marker=\"o\",\n",
        "    aspect=1.3,\n",
        ")\n",
        "axs.set_titles(\"#SpecTokens = {col_name}\")\n",
        "for ax in axs.axes.flat:\n",
        "    ax.grid(True, alpha=0.5, axis=\"y\")\n",
        "    ax.set_ylim(0, None)\n",
        "    ax.set_ylabel(\"Acceptance Length\")\n",
        "    ax.set_xlabel(\"Number of Speculative Tokens\")\n",
        "sns.move_legend(\n",
        "    axs,\n",
        "    \"right\",\n",
        "    ncol=1,\n",
        "    bbox_to_anchor=(1.02, 0.5),\n",
        "    title=\"Method\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
